---
title: "Across pilot study summarizations"
date: 'This version: March 2025'
author: "Adeline Lo"
output: 
  html_document: 
    code_folding: hide
    pandoc_args: ["--lua-filter=color-text.lua"]
    toc: true
    toc_float: true
    number_sections: true
    theme: united
  pdf_document: 
    pandoc_args: ["--lua-filter=color-text.lua"]
    keep_tex: true
header-includes:
  - \preauthor{\centering\large}
  - \predate{\centering\normalsize}
  - \pretitle{\centering\Large\textbf}
  - \usepackage{setspace}\onehalfspacing
  - \usepackage{xcolor}
  - \usepackage[shortlabels]{enumitem}
  - \usepackage{pgf,tikz, mathabx}
  - \usetikzlibrary{positioning}
editor_options:
  chunk_output_type: console
---
<style>

table, td, th {
  border: none;
  padding-left: 1em;
  padding-right: 1em;
  margin-left: auto;
  margin-right: auto;
  margin-top: 1em;
  margin-bottom: 1em;
}

</style>

```{cat, engine.opts = list(file = "color-text.lua")}
Span = function(span)
  color = span.attributes['color']
  -- if no color attribute, return unchange
  if color == nil then return span end
  
  -- tranform to <span style="color: red;"></span>
  if FORMAT:match 'html' then
    -- remove color attributes
    span.attributes['color'] = nil
    -- use style attribute instead
    span.attributes['style'] = 'color: ' .. color .. ';'
    -- return full span element
    return span
  elseif FORMAT:match 'latex' then
    -- remove color attributes
    span.attributes['color'] = nil
    -- encapsulate in latex code
    table.insert(
      span.content, 1,
      pandoc.RawInline('latex', '\\textcolor{'..color..'}{')
    )
    table.insert(
      span.content,
      pandoc.RawInline('latex', '}')
    )
    -- returns only span content
    return span.content
  else
    -- for other format return unchanged
    return span
  end
end
```

<!-- # Packages: -->

```{r,eval=TRUE,message=FALSE,warning=FALSE}
rm(list=ls())

pacman::p_load(here,Hmisc,dplyr,gridExtra,grid,stargazer,hrbrthemes,quanteda,readtext,tidyverse,knitr,papeR,tidyr,kableExtra,ggpubr,printr,tab,lfe,sjPlot,clusterSEs,BBmisc,miceadds,mediation,estimatr,sensemakr,SentimentAnalysis,ggplot2,ggridges,viridis,quanteda,quanteda.textstats,quanteda.textplots)

source(here::here("Code","R_fns.R"))

#saveRDS(data_dictionary_LSD2015,here::here("../Data","data_dictionary_LSD2015.rds")) #save `Quanteda` has an integrated sentiment dictionary called `data_dictionary_LSD2015` (Lexicoder Sentiment Dictionary) that we're using to code sentiments of texts

#color blind friendly palettes: 

# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# The palette with black:
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
set.seed(12345)
```

# Call Data
Read in data:
```{r call data}
#Study 1
data1<-readRDS(file=here::here("Data/Survey Data","Pilot Study 1","clean_data_study1.rds"))
long_data1<-readRDS(file=here::here("Data/Survey Data","Pilot Study 1","clean_long_data_study1.rds"))
#study 0 (paper=Study 2)
data2<-readRDS(file=here::here("Data/Survey Data","Pilot Study 0","clean_data2.rds"))
data2_FvD_dfm<-readRDS(file=here::here("Data/Survey Data","Pilot Study 0","FvD_dfm.rds"))#for keyness plot
data2_feel_dfm <- readRDS(file=here::here("Data/Survey Data","Pilot Study 0","feel_dfm.rds"))#for sentimenting generated texts
data2_describe_dfm <- readRDS(file=here::here("Data/Survey Data","Pilot Study 0","describe_dfm.rds"))#for sentimenting generated texts
data2_text_feel<-readRDS(file=here::here("Data/Survey Data","Pilot Study 0","data_text_feel.rds"))#for sentimenting generated texts
data2_text_describe<-readRDS(file=here::here("Data/Survey Data","Pilot Study 0","data_text_describe.rds"))#for sentimenting generated texts
data2<-subset(data2,Finished==1)
#study 2 (paper=Study 3)
data3<-readRDS(file=here::here("Data/Survey Data","Pilot Study 2","clean_data_study2.rds"))
data3$BaseEmpathy_warmperspective<-rowSums(data3[,c("BaseEmpathy_warm","BaseEmpathy_perspective")],na.rm=T)
long_data3<-readRDS(file=here::here("Data/Survey Data","Pilot Study 2","clean_long_data_study2.rds"))
long_data3$BaseEmpathy_warmperspective<-rowSums(long_data3[,c("BaseEmpathy_warm","BaseEmpathy_perspective")],na.rm=T)
#study 3
data3B<-readRDS(file=here::here("Data/Survey Data","Pilot Study 3","clean_data_study3.rds"))

#study 4 (paper=Study 4)
data4<-readRDS(file=here::here("Data/Survey Data","Pilot Study 4","clean_data_study4.rds"))
data4 <- data4[ which(data4$treat16=="empathetic" | data4$treat16=="happiness" | data4$treat16=="objective"),]

#study 5 and 6 (paper=Study 5, 5A and 5B)
data5<-readRDS(file=here::here("Data/Survey Data","Pilot Study 5","clean_data_study5.rds"))
long_data5<-readRDS(file=here::here("Data/Survey Data","Pilot Study 5","clean_long_data_study5.rds"))

data6<-readRDS(file=here::here("Data/Survey Data","Pilot Study 6","clean_data_study6.rds"))
long_data6<-readRDS(file=here::here("Data/Survey Data","Pilot Study 6","clean_long_data_study6.rds"))


##study 5: first three trials
long_data5_new<-subset(long_data5,trial=="describeORfeel1" | trial == "describeORfeel2"| trial == "describeORfeel3")
long_data5_new<- long_data5_new[!is.na(long_data5_new$happy), ]
long_data5_new<- long_data5_new[!is.na(long_data5_new$PraiseEmpathy), ]
long_data5_new<- long_data5_new[!is.na(long_data5_new$describeORfeel), ]
##study 6 (paper study 5B):
long_data6_new<- long_data6[!is.na(long_data6$PraiseEmpathy), ]
long_data6_new<- long_data6_new[!is.na(long_data6_new$happy), ]
long_data6_new<- long_data6_new[!is.na(long_data6_new$describeORfeel), ]
##pooled: set new ID
long_data5_new$ID_pool<-long_data5_new$ID
long_data6_new$ID_pool<-long_data6_new$ID+1000
long_datapool<-data.frame(ID=c(long_data5_new$ID_pool,long_data6_new$ID_pool)
           ,describeORfeel=c(long_data5_new$describeORfeel,long_data6_new$describeORfeel)
           ,happy=c(long_data5_new$happy,long_data6_new$happy)
           ,PraiseEmpathy=c(long_data5_new$PraiseEmpathy,long_data6_new$PraiseEmpathy), Party=c(long_data5_new$Party,long_data6_new$Party)
)

#study PE (paper Study 6 "Peer praise and empathy towards racial outgroups")
data6PE<-readRDS(file=here::here("Data/Survey Data","Pilot Study 1PE","clean_data_study1PE.rds"))
long_data6PE<-readRDS(file=here::here("Data/Survey Data","Pilot Study 1PE","clean_longdata_study1PE.rds"))


#study 7 DLABSS May 2022 (paper "Co-Partisan Praise" Study 7)
data7<-readRDS(file=here::here("Data/Survey Data","Pilot DLABSS May-June 2022","data.rds"))
data7_attentive<-readRDS(file=here::here("Data/Survey Data","Pilot DLABSS May-June 2022","data_attentive.rds"))

# read in Quanteda Lexicoder Sentiment Dictionary saved
data_dictionary_LSD2015<-readRDS(here::here("Data","data_dictionary_LSD2015.rds"))
```

Information to create SI Table B.1: ADD S6, S7

```{r sumtable}
#study 4 n from praisefeel,praisedescribe, control arms: 83+13+127=223
sumtable<-data.frame(Study=1:5
           ,Treatment=c("-","-","Peer praise","Peer praise","Peer praise mediated by happiness")
           ,N=c(nrow(data1),nrow(data2),nrow(data3),nrow(data4),(nrow(data5)+nrow(data6))))

studies<-data.frame(Study=c("Study 1","Study 2", "Study 3", "Study 4","Study 5A","Study 5B", "Total")
                    ,Goal=c("Costliness of empathy","Eliciting peer praise","Peer praise on empathy","Happiness as mediator","Mediation analysis","Mediation analysis","-")
                    ,Total_N=c(nrow(data1),nrow(data2),nrow(data3),nrow(data4),nrow(data5),nrow(data6),sum(c(nrow(data1),nrow(data2),nrow(data3),nrow(data4),nrow(data5),nrow(data6))))
                    ,Total_T=c(3,"-",15,1,20,3,"-")
                    ,Total_obs=c(nrow(long_data1),nrow(data2) #1,2
                                 ,(1559+1561+1560),nrow(data4) #3,4
                                 ,(3238+3242),(866+865)
                                 ,sum(c(nrow(long_data1),nrow(data2),(1559+1561+1560),nrow(data4),(3238+3242),(866+865))))
)

#LaTeX table
kable(studies, booktabs = T, 
      #caption = "Summarizing information on studies.",
      label="sumtable" ,"latex"
      ,col.names = c("","Study goal","N","Trials","Total obs."))%>% 
  kable_styling(latex_options = c("striped", "scale_down"),position = "center",font_size=12)%>%#, "scale_down"
  row_spec(0, bold = T) %>%
  column_spec(1, bold = T, color = "black", width="2cm") %>%
  column_spec(2, width = "4cm")%>% #goal
  column_spec(3, width = "2cm")%>% #total n
  column_spec(4, width = "1.5cm")
```

# Study 1

## Study 1 Covariate summary table

Information to create SI Table B.2:

```{r otherstats1}
#mean, range of age
summary(as.numeric(data1$age))
#sd age
sd(as.numeric(data1$age),na.rm=T)
#percent gender
prop.table(table(data1$Sex,useNA='always'))
#percent race
prop.table(table(data1$Race,useNA='always'))
#percent education
prop.table(table(data1$Education,useNA='always'))

#covariate table part 1
kable(summarize(data1, type = "factor", variables = c( "Sex",
                                                      "Race", "Education",
                                                      "Income","Religion", 
                                                      "Party", "Ideology"
                                                     ))
    ,
    booktabs=TRUE,"latex",longtable=FALSE) %>% kable_styling(latex_options = c("striped", "hold_position","repeat_header"))
  
#covariate table part 2
data1$Age<-as.numeric(data1$age)
kable(summarize(data1, type = "numeric", variables = "Age"),booktabs=TRUE,"latex",longtable=FALSE) %>% 
  kable_styling(latex_options = c("striped", "hold_position","repeat_header")) 
#combine covariate tables 1 and 2, then add in caption: "\bf Study 1 Respondents (Summarizing covariates)}. Total number of respondents 318."
#may need to adjust LaTeX font of table to scriptsize; adjust Missing text
```


## Study 1 Descriptive statistics & Task summary

Create SI Table B.3:

```{r}
#post13_1 choose task FEEL
#post14_1 choose task DESCRIBE
#post15_1 empathy good
#post16_1 objectivity good
data1$post13_1_new<-as.numeric(data1$post13_1)
data1$post14_1_new<-as.numeric(data1$post14_1)
data1$post15_1_new<-as.numeric(data1$post15_1)
data1$post16_1_new<-as.numeric(data1$post16_1)

disc_table <- dplyr::select(data1,
                     c(post13_1_new,post14_1_new,
                       post15_1_new,post16_1_new))

## SI Table B.3
stargazer(as.data.frame(disc_table),summary=T,
          covariate.labels = c("Belief people choose Feel task",
                               "Belief people choose Describe task",
                               "Belief people think empathy is good",
                               "Belief people think objectivity is good"),
          title = "Descriptive Statistics - Empathy norms",iqr=T,digits=3,
         style = "ajps", type = "latex",label="tab:empathy_norms")
```


Create SI Table B.4:

```{r}
#post3 mentally demanding describe
#post4 hard to accomplish describe
#post5 insecure discouraged describe
#post6 successful at describe
#post7 mentally demanding feel
#post8 hard to accomplish feel
#post9 insecure discouraged feel
#post10 successful at feel

data1$post3n<-as.numeric(data1$post3)
data1$post4n<-as.numeric(data1$post4)
data1$post5n<-as.numeric(data1$post5)
data1$post6n<-as.numeric(data1$post6)
data1$post7n<-as.numeric(data1$post7)
data1$post8n<-as.numeric(data1$post8)
data1$post9n<-as.numeric(data1$post9)
data1$post10n<-as.numeric(data1$post10)

## SI Table B.4
disc_table <- dplyr::select(data1,
                     c(post3n,post7n,post4n,post8n,
                       post5n,post9n,post6n,post10n))

stargazer(as.data.frame(disc_table),summary=T,
          covariate.labels = c("Describe task mentally demanding", 
                               "Feel task mentally demanding",
                               "Describe task hard to accomplish",
                               "Feel task hard to accomplish",
                               "Describe task raised insecurity",
                               "Feel task raised insecurity",
                               "Describe task done successfuly",
                               "Feel task done successfuly"),
          title = "Descriptive Statistics - NASA task load",iqr=T,digits=3,
         style = "ajps", type = "latex",label="tab:nasa2")


```

Create SI Table B.5:

```{r}
evaltask_data<-data.frame(ID=data1$ID, Task=rep(c("DESCRIBE","FEEL"),each=nrow(data1))
                          ,Demanding=as.numeric(c(data1$post3,data1$post7))
                          ,Hard=as.numeric(c(data1$post4,data1$post8))
                          ,Insecure=as.numeric(c(data1$post5,data1$post9))
                          ,Successful=as.numeric(c(data1$post6,data1$post10)))
tmp_colors<-viridis(n=2,alpha=0.6,begin=0.25,end=1,direction=1,option="D")
tmp_colors<-viridis(n=3,begin=0.25,end=1,direction=1,alpha=0.75,option="D")

#
t_demand<-t.test(Demanding~Task, data=evaltask_data)
t_hard<-t.test(Hard~Task, data=evaltask_data)
t_insecure<-t.test(Insecure~Task, data=evaltask_data)
t_successful<-t.test(Successful~Task, data=evaltask_data)
#table of describe vs feel for demanding/hard/insecure/successful
tmp_d<-data.frame(Task=c("Objective (DESCRIBE)","Empathy (FEEL)","Difference")
           ,Demanding=c(round(tapply(evaltask_data$Demanding,evaltask_data$Task,mean,na.rm=TRUE),3),paste(round(t_demand$estimate[2]-t_demand$estimate[1],3)," (p=",round(t_demand$p.value,4),")",sep=""))
           ,Hard=c(round(tapply(evaltask_data$Hard,evaltask_data$Task,mean,na.rm=TRUE),3),paste(round(t_hard$estimate[2]-t_hard$estimate[1],3)," (p=",round(t_hard$p.value,4),")",sep=""))
           ,Insecure=c(round(tapply(evaltask_data$Insecure,evaltask_data$Task,mean,na.rm=TRUE),3),paste(round(t_insecure$estimate[2]-t_insecure$estimate[1],3)," (p=",round(t_insecure$p.value,4),")",sep=""))
           ,Successful=c(round(tapply(evaltask_data$Successful,evaltask_data$Task,mean,na.rm=TRUE),3),paste(round(t_successful$estimate[2]-t_successful$estimate[1],3)," (p=",round(t_successful$p.value,4),")",sep="")))
rownames(tmp_d)<-NULL

#LaTeX version
kable(tmp_d
      , caption = "Task load summary. Mean values reported (choices from 1-5). Difference row conducts two-sample t-tests at alpha of 0.05 without multiple comparisons adjustments.","latex",booktabs=T) %>%
  kable_styling(latex_options=c("striped","hold_position"),full_width=F,font_size=12)%>%
  row_spec(0, bold = T)

```


## Study 1 Attrition
Create SI Figure B.4:

```{r attrition-s1 data}
#select relevant questions
attrite1<- data1[, c("consent", 
                       "cards1", "pa", "pb_1", "pb_2", "pb_3", "pc", 
                       "cards2", "p2a", "p2b_1", "p2b_2", "p2b_3", "p2c",
                       "cards3",  "Aa", "Ab_1", "Ab_2", "Ab_3", "Ac",
                       "cards4",  "Ba", "Bb_1", "Bb_2", "Bb_3", "Bc",
                       "cards5", "Ca", "Cb_1", "Cb_2", "Cb_3", "Cc",
                       "pair1r_1", "pair2r_1","pair3r_1", 
                       "pair4r_1", "pair5r_1", "pair6r_1",
                       "pair7r_1", "pair8r_1", "pair9r_1", 
                       "pair10r_1", "pair11r_1", "pair12r_1",
                       "Q295", "Q296_1", "Q296_2", "Q296_3", 
                       "Q297", "post1", "post2", "post3",
                    "post4", "post5", "post6", "post7", 
                    "post8", "post9", "post10",
                    "post11_1","post11_2","post11_3","post11_4",
                    "post11_5","post11_6","post11_7","post11_8",
                    "post13_1", "post14_1", "post15_1", "post16_1", "post17", 
                    "age","sex","race","education",
                    "income","religion","part_id","ideology", "state", "pres_approval"
                    )]


plot_attrition(data = attrite1
               ,treatment = "Cc" #randomization between real and hypothetical wage tasks
               ,DV = c(paste("cards",3:5,sep=""),paste("pair",1:12,"r_1",sep="")) #choice of deck main task, then task for real wage task.
               ,freq = FALSE
               )  + ylim(0,1)
#Add to Figure Legend: Attrition across survey questions: X axis denotes survey questions in chronological order. Blue vertical lines mark outcome questions: open-ended, three short words, and a feeling thermometer, which followed the behavioral empathy tasks. Red vertical line represents randomization of hypothetical and real wage tasks. Y axis is the proportion of total n attrited, calculated as number of attrited respondents / total n.

ggsave("Figures/attrition_1.pdf",  width = 11, height = 6)
#Figures/attrition_1.pdf 11x6

attrition(attrite1) #67/318

```





# Study 2
## Study 2 Covariate summary table

Information to create SI Table B.6:

```{r otherstats2}
#mean, range of age
summary(as.numeric(data2$age))
#sd age
sd(as.numeric(data2$age),na.rm=T)
#percent gender
prop.table(table(data2$Sex,useNA='always'))
#percent race
prop.table(table(data2$Race,useNA='always'))
#percent education
prop.table(table(data2$Education,useNA='always'))

#covariate table part 1
kable(summarize(data2, type = "factor", variables = c( "Sex",
                                                      "Party", "Ideology",
                                                      "Race","Education", 
                                                      "Income", "Religion"
                                                     ))
    ,caption="Study 2 Respondents"
    ,booktabs=TRUE,"latex",longtable=FALSE) %>% kable_styling(latex_options = c("striped", "hold_position","repeat_header"))

#covariate table part 2
data2$Age<-as.numeric(data2$age)
kable(summarize(data2, type = "numeric", variables = "Age"),booktabs=TRUE,"latex",longtable=FALSE) %>% 
  kable_styling(latex_options = c("striped", "hold_position","repeat_header"))

#combine covariate tables 1 and 2, then add in caption: "\bf Study 2 Respondents}. Total number of respondents 114"
#may need to adjust LaTeX font of table to scriptsize; adjust Missing text

```

## Study 2 Keyness

Create SI Figure B.6:

```{r}
## compare target Therm H group to rest of dtm (Therm L)
keyness=quanteda.textstats::textstat_keyness(data2_FvD_dfm,target="FEEL")
pdf(file=here::here("Figures","keyness_FvD.pdf"),width=8,height=8)
quanteda.textplots::textplot_keyness(
  keyness,
  show_reference = TRUE,
  show_legend = TRUE,
  n = 20L,
  min_count = 2L,
  margin = 0.05,
  color = c("darkblue", "gray"),
  labelcolor = "gray30",
  labelsize = 4,
  font = NULL
)
dev.off()

#Add to caption: {\bf Keyness plot of words for empathy (\textsc{feel}) versus objective (\textsc{describe}) tasks.} Figure plots the results of a keyword of features comparing their differential associations with providing language in praise of peers who engage in empathy (\textsc{feel}) versus objective (\textsc{describe}) tasks, after calculating ``keyness'', a score for features that occur differentially across different categories. Here text for (\textsc{feel}) and (\textsc{describe}) are the different categories.
```

## Study 2 Sentiments and Thermometer

Create SI Figure B.7:

```{r}
#create sentiment dfm for feel
sent_feel_dfm <- dfm_lookup(data2_feel_dfm, dictionary= data_dictionary_LSD2015[1:2])
sent_feel_df<-convert(sent_feel_dfm, to = "data.frame")
#paste in feel sentiment df thermometer response
sent_feel_df$thermometer<-data2_text_feel$FEEL_4

#create sentiment dfm for describe
sent_describe_dfm <- dfm_lookup(data2_describe_dfm, dictionary= data_dictionary_LSD2015[1:2])
sent_describe_df<-convert(sent_describe_dfm, to = "data.frame")
#paste in describe sentiment df thermometer response
sent_describe_df$thermometer<-data2_text_describe$DESCRIBE_4#[match(sent_describe_df$document,data_text_describe$doc_id)]

#How are text sentiments and the thermometer related?
# linear trend + confidence interval
tmp_col<-viridis(3,begin=0,end=1,direction=1,option="D", alpha=0.65)
p1<-ggplot(sent_feel_df, aes(x=positive, y=thermometer)) + ylim(0,10) +
  #geom_jitter(alpha=0.5,width = 0.2, height = 0.2) +
  geom_point(position = position_jitter(seed = 12345),alpha=0.5,width = 0.2, height = 0.2) +
  geom_smooth(method=lm , color=cbPalette[1], fill=tmp_col[3], se=TRUE) +
  theme_bw()

p2<-ggplot(sent_feel_df, aes(x=negative, y=thermometer)) + ylim(0,10) +
  #geom_jitter(alpha=0.5,width = 0.2, height = 0.2) +
  geom_point(position = position_jitter(seed = 12345),alpha=0.5,width = 0.2, height = 0.2) +
  geom_smooth(method=lm , color=cbPalette[1], fill=tmp_col[3], se=TRUE) +
  theme_bw()

pdf(file=here::here("Figures","linear_sentiment_feel_thermometer.pdf"),width=8,height=8)
grid.arrange(p1,p2,nrow=1)
dev.off()
#For caption of figure: Correlation between positive and negative text sentiments for generated texts of praise for empathetic behavior with thermometer ratings for people who engage in empathetic behavior plotted as linear regression \texttt{lm} in R with 95\% confidence band.
```

Create SI Figure B.8
```{r}
#How are text sentiments and the thermometer related?
# linear trend + confidence interval
tmp_col<-viridis(3,begin=0,end=1,direction=1,option="D", alpha=0.65)
p1<-ggplot(sent_describe_df, aes(x=positive, y=thermometer)) + ylim(0,10) +
  geom_point(position = position_jitter(seed = 12345),alpha=0.5,width = 0.2, height = 0.2) +
  geom_smooth(method=lm , color=cbPalette[1], fill=tmp_col[2], se=TRUE) +
  theme_bw()

p2<-ggplot(sent_describe_df, aes(x=negative, y=thermometer)) + ylim(0,10) +
  geom_point(position = position_jitter(seed = 12345),alpha=0.5,width = 0.2, height = 0.2) +
  geom_smooth(method=lm , color=cbPalette[1], fill=tmp_col[2], se=TRUE) +
  theme_bw()

pdf(file=here::here("Figures","linear_sentiment_describe_thermometer.pdf"),width=8,height=8)
grid.arrange(p1,p2,nrow=1)
dev.off()

#For caption of figure: Correlation between positive and negative text sentiments for generated texts of praise for objective behavior with thermometer ratings for people who engage in objective behavior plotted as linear regression \texttt{lm} in R with 95\% confidence band.
```

Create SI Figure B.9

```{r}
tmp_col<-viridis(3,begin=0.3,end=1,direction=1,option="D", alpha=0.65)
plotdata<-data.frame(feel=c(data2_text_feel$FEEL_4),describe=c(data2_text_describe$DESCRIBE_4))
p <- ggplot(plotdata, aes(x=x) ) +
  geom_histogram( aes(x = feel, y = ..density..), fill="gold2", binwidth = 0.5,alpha=0.7) +
  geom_label( aes(x=4.5, y=0.35, label="Average Feel: 7.92"), color="gold2") + ylim(-0.6,0.6)+
  geom_histogram( aes(x = describe, y = -..density..), fill= "darkcyan", binwidth = 0.5, alpha=0.7) +
  geom_label( aes(x=4.5, y=-0.35, label="Average Describe: 7.21"), color="darkcyan") +
  theme_bw() +
  xlab("thermometer")

pdf(file=here::here("Figures","thermometer_density.pdf"),width=8,height=6)
p
dev.off()
```



## Study 2 Attrition
No attrition occurred.

Create SI Figure B.10:

```{r attrition-s2 data}
#select relevant questions
attrite2<- data2[, c("consent",
                       "FEEL_2_1","FEEL_2_2","FEEL_2_3","FEEL_3","FEEL_4",
                     "mf_1_1","mf_2a","mf_2b_1","mf_2b_2","mf_2b_3","mf_3_1","mf_4a","mf_4b","mf_5",
                       "DESCRIBE_2_1","DESCRIBE_2_2","DESCRIBE_2_3","DESCRIBE_3","DESCRIBE_4",
                     "md_1_1","md_2a","md_2b_1","md_2b_2","md_2b_3","md_3_1","md_4a","md_4b","md_5",
                       "age","sex","race","education","income","religion","part_id","ideology")]

plot_attrition(data = attrite2
               #,treatment = 
               #,pre_treatment = c("cards_a", "cards_b") #practice round
               #,DV = c(paste("cards",1:15,sep=""),"task") #choice of deck main task, then task for real wage task.
               ,freq = FALSE
               )   + ylim(0,1)
ggsave(here::here("Figures","attrition_2.pdf"),  width = 8, height = 5)
#no attrition occurred

attrition(attrite2)#0
```

# Study 3
## Study 3 Covariate summary table

Information to create SI Table B.7:

```{r sumcovariates3}
#Latex Table of Covariates for Study 3:
#covariate table part 1
kable(summarize(data3, type = "factor", variables = c( "Sex",
                                                      "Party", "Ideology",
                                                      "Race","Education", 
                                                      "Income", "Religion"
                                                     ))
    ,caption="Study 3 Respondents",label="tab:s3_covariates1"
    ,booktabs=TRUE,"latex",longtable=FALSE) %>% kable_styling(latex_options = c("striped", "hold_position","repeat_header"))
#covariate table part 2
data3$Age<-as.numeric(data3$age)
kable(summarize(data3, type = "numeric", variables = "Age"),booktabs=TRUE,"latex",longtable=FALSE) %>% kable_styling(latex_options = c("striped", "hold_position","repeat_header"))
#combine covariate tables 1 and 2, then add in caption: "\bf Study 3 Respondents (Summarizing covariates)}. Total number of respondents 328. "
#may need to adjust LaTeX font of table to scriptsize; adjust Missing text
```

Other notes that appear in the main text:

```{r otherstats3}
#mean, range of age
summary(as.numeric(data3$age))
#sd age
sd(as.numeric(data3$age))
#percent gender
prop.table(table(data3$Sex,useNA='always'))
#percent race
prop.table(table(data3$Race,useNA='always'))
#percent education
prop.table(table(data3$Education,useNA='always'))
```

## Study 3 Peer praise for empathy effect on choosing FEEL
SI Table B.8:

```{r praiseempathy}
#Praise-feel vs Control
ate1 <- miceadds::glm.cluster( data=long_data3, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate1) #log odds output: baseline log odds of choosing empathy task is -0.44; difference in log-odds of choosing empathy and objective tasks is 0.182 -- peer-praised group has [log-odds to odds-ratio: exp(log-odds)] exp(0.1819)=1.20 times the odds of choosing empathy over objective task as the control group. [Odds ratio to %: (OR-1) * 100] Peer-praised group has a 20% greater likelihood of choosing empathy task over objective task compared to control group. p=0.02
##GLM logit exponentiated coefficient estimate
round(summary(ate1)[2,1],3)
#z
round(summary(ate1)[2,3],3)
#p
round(summary(ate1)[2,4],3)
#CI
confint(ate1)

### "Here, we found that the peer-praise group was 20\% more likely to choose empathy compared to a control group that did not receive praise "

#praise-feel vs praise-describe
ate2 <- miceadds::glm.cluster( data=long_data3, formula=describeORfeel ~ PraiseEmpathy_a,
               cluster="ID", family=binomial(link="logit"))
summary(ate2)#log odds output: baseline of choosing empathy is -0.336; differences in log-odds of choosing empathy and objective tasks is 0.106. p=0.16

```

SI Table B.8 & SI Table B.9 : summarizing log odds, odds ratio, %.

```{r praiseempathy table}
alpha2=0.05/2
#rows=intercept, praise
praisetable<-data.frame(LO=coef(ate1)
  ,CIlow_LO=c(coef(ate1)[1] - qnorm(1-alpha2)*0.09344624,coef(ate1)[2] - qnorm(1-alpha2)*0.08020047)
  ,CIup_LO=c(coef(ate1)[1] + qnorm(1-alpha2)*0.09344624,coef(ate1)[2] + qnorm(1-alpha2)*0.08020047)
  ,OR=exp(coef(ate1))
  ,CIlow_OR=exp(coef(ate1) - qnorm(1-alpha2)* c(0.09344624,0.08020047))
  ,CIup_OR=exp(coef(ate1) + qnorm(1-alpha2)* c(0.09344624,0.08020047)))
praisetable$CI_LO<-paste("[",round(praisetable$CIlow_LO,3),",",round(praisetable$CIup_LO,3),"]",sep="")
praisetable$CI_OR<-paste("[",round(praisetable$CIlow_OR,3),",",round(praisetable$CIup_OR,3),"]",sep="")
#LaTeX table
tmp<-praisetable[,c("LO","CI_LO","OR","CI_OR")]
rownames(tmp)<-c("Intercept","Peer praise for empathy (v. control)")
kable(tmp, booktabs = T, caption = "Peer praise for empathy effect on choosing \textsc{feel} in main behavioral empathy task, compared to control condition.",label="praisetable" ,"latex"
      ,col.names = c("Log Odds","95% CI","Odds Ratio","95% CI"),digits=3)%>% 
  kable_styling(latex_options = c("striped", "scale_down"),position = "center",font_size=12)%>%#, "scale_down"
  row_spec(0, bold = T) %>%
  column_spec(1, bold = T, color = "black", width="3cm") %>%
  column_spec(2, width = "2cm")%>% 
  column_spec(3, width = "3cm")%>% 
  column_spec(4, width = "2cm")

#repeat for praise-describe v praise-feel
praisetable<-data.frame(LO=coef(ate2)
  ,CIlow_LO=c(coef(ate2)[1] - qnorm(1-alpha2)*0.09344624,coef(ate2)[2] - qnorm(1-alpha2)*0.08020047)
  ,CIup_LO=c(coef(ate2)[1] + qnorm(1-alpha2)*0.09344624,coef(ate2)[2] + qnorm(1-alpha2)*0.08020047)
  ,OR=exp(coef(ate2))
  ,CIlow_OR=exp(coef(ate2) - qnorm(1-alpha2)* c(0.09344624,0.08020047))
  ,CIup_OR=exp(coef(ate2) + qnorm(1-alpha2)* c(0.09344624,0.08020047)))
praisetable$CI_LO<-paste("[",round(praisetable$CIlow_LO,3),",",round(praisetable$CIup_LO,3),"]",sep="")
praisetable$CI_OR<-paste("[",round(praisetable$CIlow_OR,3),",",round(praisetable$CIup_OR,3),"]",sep="")
#LaTeX table
tmp<-praisetable[,c("LO","CI_LO","OR","CI_OR")]
rownames(tmp)<-c("Intercept","Peer praise for empathy (v. praise-describe)")
kable(tmp, booktabs = T, caption = "Peer praise for empathy effect on choosing \textsc{feel} in main behavioral empathy task, compared to peer praise Describe.",label="praisetable2" ,"latex"
      ,col.names = c("Log Odds","95% CI","Odds Ratio","95% CI"),digits=3)%>% 
  kable_styling(latex_options = c("striped", "scale_down"),position = "center",font_size=12)%>%#, "scale_down"
  row_spec(0, bold = T) %>%
  column_spec(1, bold = T, color = "black", width="3cm") %>%
  column_spec(2, width = "2cm")%>% 
  column_spec(3, width = "3cm")%>% 
  column_spec(4, width = "2cm")

```

```{r praiseempathy-plot}
praisetable$group<-c("Control","Peer praise")
praisetable$OR2<-c(exp(coef(ate1)[1]),exp(sum(coef(ate1)))) #this is the summative exponeniated ver for or in praise (not effect)
praisetable$CIlow_OR2<- praisetable$OR2 - qnorm(1-alpha2)* c(0.09344624,0.08020047)
praisetable$CIup_OR2<- praisetable$OR2 + qnorm(1-alpha2)* c(0.09344624,0.08020047)
ggplot(praisetable) +
  geom_bar(aes(x=group, y=OR2), stat="identity"
           ,fill=viridis(2,begin=0.25,end=1,direction=1,option="D", alpha=0.9)) +
  geom_linerange( aes(x=group, ymin=CIlow_OR2, ymax=CIup_OR2), colour="gray20", alpha=0.7, size=1) +
  geom_text(x=1,y=0.9,label=round(praisetable$OR2[1],3), colour="gray20",size=5) +
  geom_text(x=2,y=1.0,label=round(praisetable$OR2[2],3), colour="gray20",size=5) +
  geom_text(x=1.5,y=1.1
            ,label=paste("Difference: ",round(praisetable$OR2[2]-praisetable$OR2[1],3)," (p=0.02)",sep="")
            ,color="gray20",size=5) +
  ggtitle(" ") + theme_bw() + ylim(0,1.1) + ylab("Odds ratio choosing empathy task") + xlab(" ") +
  theme(axis.text.x=element_text(size=12), axis.title.y=element_text(size=12))  +
    scale_x_discrete(labels= c("Control","Peer praise empathy"))
#ate_praiseempathy.pdf
```

SI Section B.6 Pilot Study 3: Praise Lowers the Cost of Empathy -- summaries of LM models.

```{r,eval=TRUE,message=FALSE,warning=FALSE}
#"When primed with praise for the feel task, respondents are \hl{4.4\% (p=0.023, estimate=0.044, CI$[0.006, 0.082]$)} more likely to select the Feel task (baseline is 0.391) "
model_1a <- miceadds::lm.cluster( data=long_data3, formula=describeORfeel ~ PraiseEmpathy, cluster="ID" )
summary(model_1a)
confint(model_1a)

#"When compared to the praise-describe condition, respondents primed with praise for the feel task, respondents are 2.6%... more likely to select the Feel task..".
model_1b <- miceadds::lm.cluster( data=long_data3, formula=describeORfeel ~ PraiseEmpathy_a,
               cluster="ID" )
summary(model_1b)
confint(model_1b)


```

## Study 3 Attrition

Create SI Figure B.12 Attrition across survey questions, and information in text on attrition:

```{r attrition-s3 data}
##praise on attrition in study 2 (3 in paper)
#"Respondents who randomly given the peer praise for empathy were $0.5\%$ less likely to attrite (baseline is $0.01$)"
attrite_praise <- lm_robust(attrite ~ PraiseEmpathy,
               clusters = ID, data = long_data3)
summary(attrite_praise)
confint(attrite_praise)

#race image on attrition in study 2 (3 in paper)
#Respondents who saw an image with a black person, were $0.2\%$ less likely to attrite (baseline is $0.007$) than compared to respondents who received an image with a white person \hl{(estimate=$-0.002$, p=$0.377$, t=$-0.8854$, CI$[-0.006, 0.002]$)}.
attrite_race <- lm_robust(attrite ~ race_randomized2,
               clusters = ID, data = long_data3)

summary(attrite_race)
confint(attrite_race)

#image valence on attrition in study 2 (3 in paper)
#Respondents who saw an image with an angry person, were $0.1\%$ less likely to attrite (baseline is $0.006$) than compared to respondents who received an image with a fearful person \hl{(estimate=$-0.0006$, p=$0.775$, t=$-0.286$, CI$[-0.005, 0.004]$)}.
attrite_valence <- lm_robust(attrite ~ emotion_randomized2,
               clusters = ID, data = long_data3)

summary(attrite_valence)
confint(attrite_valence)
#select relevant questions
attrite3<- data3[, c("consent", 
                       "cards_a", "pa", "pb_1", "pb_2", "pb_3", "pc", 
                       "cards_b", "p2a", "p2b_1", "p2b_2", "p2b_3", "p2c",
                     "treat1",#treatment1
                       "cards1",  "Aa", "Ab_1", "Ab_2", "Ab_3", "Ac",
                     "treat2",#treatment2
                       "cards2",  "Ba", "Bb_1", "Bb_2", "Bb_3", "Bc",
                     "treat3",#treatment3
                       "cards3", "Ca", "Cb_1", "Cb_2", "Cb_3", "Cc",
                     "treat4",#treatment4
                       "cards4",  "Q415", "Q418_1", "Q418_2", "Q418_3", "Q421",
                     "treat5",#treatment5
                       "cards5", "Q427", "Q430_1", "Q430_2", "Q430_3", "Q433",
                     "treat6",#treatment6
                       "cards6", "Q436", "Q439_1", "Q439_2", "Q439_3", "Q442",
                     "treat7",#treatment7
                       "cards7", "Q448", "Q451_1", "Q451_2", "Q451_3", "Q454",
                     "treat8",#treatment8
                       "cards8", "Q460", "Q463_1", "Q463_2", "Q463_3", "Q466",
                     "treat9",#treatment9
                       "cards9", "Q472", "Q475_1", "Q475_2", "Q475_3", "Q478",
                     "treat10",#treatment10
                       "cards10", "Q484", "Q487_1", "Q487_2", "Q487_3", "Q490",
                     "treat11",#treatment11
                       "cards11", "Q496", "Q499_1", "Q499_2", "Q499_3", "Q502",
                     "treat12",#treatment12
                       "cards12", "Q508", "Q511_1", "Q511_2", "Q511_3", "Q514",
                     "treat13",#treatment13
                       "cards13", "Q520", "Q523_1", "Q523_2", "Q523_3", "Q526",
                     "treat14",#treatment14
                       "cards14", "Q532", "Q535_1", "Q535_2", "Q535_3", "Q538",
                     "treat15",#treatment15
                       "cards15", "Q544", "Q547_1", "Q547_2", "Q547_3", "Q550",
                     "task",
                       "pair1r_1", "pair2r_1","pair3r_1", 
                       "pair4r_1", "pair5r_1", "pair6r_1",
                       "pair7r_1", "pair8r_1", "pair9r_1", 
                       "pair10r_1", "pair11r_1", "pair12r_1",
                       "Q295", "Q296_1", "Q296_2", "Q296_3", 
                       "Q297", "post1", "post2", "post3",
                    "post4", "post5", "post6", "post7", 
                    "post8", "post9", "post10",
                    "post11_1","post11_2","post11_3","post11_4",
                    "post11_5","post11_6","post11_7","post11_8",
                    "post13_1", "post14_1", "post15_1", "post16_1", "post17", 
                    "age","sex","race","education",
                    "income","religion", "pres_approval",
                    "ideology", "part_id")] #, "donation")]

#create attrition dataset
#attrition_dataset<-attrition(data = attrite3)


plot_attrition(data = attrite3
               ,treatment = c(paste("treat",1:15,sep="")) #praise-feel,praise-describe,control for 15 main tasks and 1 real wage task
               ,pre_treatment = c("cards_a", "cards_b") #practice round
               ,DV = c(paste("cards",1:15,sep=""),"task") #choice of deck main task, then task for real wage task.
               ,freq = FALSE
               )   + ylim(0,1)
ggsave("Figures/attrition_3.pdf",  width = 16, height = 8)
#Figures/attrition_3.pdf 11x6

attrition(attrite3)#75/328
```

## Study 3 Robustness checks

Create SI Table B.10:

Are people who we "praise into empathy" doing a less good job? Compare FEEL responses under control to FEEL responses under praise. Use sentiment analysis and duration data. 
```{r}
# Set up data
#combine text answers in long data form
long_data3$text<- paste(long_data3$text1, long_data3$text2, 
                          long_data3$text3, long_data3$text4, sep=" ")
#subset only FEEL responses
long_data3_FEEL <- subset(long_data3, describeORfeel == 1)

#create corpus
write.csv(long_data3_FEEL, "Data/Survey Data/Pilot Across Studies/long_data3_FEEL.csv")
data_text_long <-readtext("Data/Survey Data/Pilot Across Studies/long_data3_FEEL.csv", text_field = c("text"))

data_text_corpus <- corpus (data_text_long)
data_text_corpus<-tokens(data_text_corpus, remove_punct = TRUE)
data_text_corpus<-tokens_select(data_text_corpus, pattern = stopwords("en"), selection = "remove")
data_text_corpus <- quanteda::tokens_wordstem(data_text_corpus)
data_text_corpus <- quanteda::tokens_tolower(data_text_corpus)

#save unique tokens in data_FEEL for test 1 using ntype()
long_data3_FEEL$unique_tokens<-quanteda::ntype(data_text_corpus)

#get 50 words from praise-feel wordcloud
feel_dfm <- readRDS(file=here::here("Data/Survey Data/Pilot Study 0/feel_dfm.rds"))
cloud_PraiseFeel <- dfm_select(feel_dfm, names(topfeatures(feel_dfm, n = 50)))
cloud_PraiseFeel <- featnames(cloud_PraiseFeel)

#percentage of cloud words from answer (per respondent)

lemma <- rep("cloudword", length(cloud_PraiseFeel))
toks2 <- tokens_replace(data_text_corpus, cloud_PraiseFeel, lemma, valuetype = "fixed") #change relevant words to "cloudword"
toks2_dfm<-dfm(toks2)
toks2_dfm<-convert(toks2_dfm, to = "data.frame")
toks2_dfm$doc_id<-NULL
toks2_dfm$sum=rowSums(cbind(toks2_dfm))
toks2_dfm$cloudword_proportion<-as.numeric(toks2_dfm$cloudword)/toks2_dfm$sum

#save cloudword_proportion in long_data3_FEEL for test 2
long_data3_FEEL$cloudword_proportion<-toks2_dfm$cloudword_proportion

#sentiment of the words
long_data3_FEEL$text_sentiment<-analyzeSentiment(long_data3_FEEL$text)$SentimentQDAP

#**Test 1**

#We check if respondents who chose FEEL under praise-feel treatment are more likely to use more diverse (unique) words than respondents who chose FEEL under the control treatment

shortcut1 <- miceadds::lm.cluster( data=long_data3_FEEL, formula=unique_tokens ~ PraiseEmpathy,
               cluster="ID" )
summary(shortcut1)

#no evidence of using fewer unique words

#**Test 2**

#We check if respondents who chose FEEL under praise-feel treatment are more likely to use words from the Praise-Feel wordcloud than respondents who chose FEEL under the control treatment

shortcut2 <- miceadds::lm.cluster(data=long_data3_FEEL, formula=cloudword_proportion ~ PraiseEmpathy,cluster="ID" )
summary(shortcut2)

#no evidence of relying on praise-feel wordcloud to shortcut

#**Test 3** 

#Check if sentiment of words is more negative in the peer-praise to feel than the control to feel groups -- suggesting not actually empathizing.

shortcut3 <- miceadds::lm.cluster(data=long_data3_FEEL, formula=text_sentiment ~ PraiseEmpathy,cluster="ID" )
summary(shortcut3)

#no evidence of using different sentiments in words to shortcut
latex_table<-cbind(summary(shortcut1),summary(shortcut2),summary(shortcut3)) 
latex_table<-latex_table[,c(-3,-7,-11)]#remove t val cols
latex_table[,c(1,2,4,5,7,8)]<-round(latex_table[,c(1,2,4,5,7,8)],3)#est,se
latex_table[,c(3,6,9)]<-signif(latex_table[,c(3,6,9)], digits = 3)#p
latex_table<-cbind(c("Intercept","Peer praise"),latex_table)
rownames(latex_table)<-NULL
#LaTeX table
kable(latex_table, booktabs = T, caption = "Testing for shortcutting.",label="shortcut" ,"latex"
      ,col.names = c("",rep(c("Estimate","s.e.","p"),3)))%>% 
  kable_styling(latex_options = c("striped", "scale_down"),position = "center",font_size=12)%>%#, "scale_down"
  add_header_above(c(" " = 1, "DV: Unique tokens" = 3, "DV: Proportion of wordcloud" = 3, "DV: Text sentiment" = 3)) %>%
  row_spec(0, bold = T) %>%
  column_spec(1, bold = T, color = "black", width="3cm") %>%
  column_spec(2:10, width = "2cm")#%>% #est

#Add into SI Table B.10 caption: Testing for shortcutting. Each test is an OLS coefficient test from OLS regression of the DV on Peer Praise with clustered standard errors at the individual level.
```

## Study 3 Explorations of other mechanisms for peer praise on empathy

Anxiety: do people become more anxious after they choose the empathy task?

- (1) difference between `anxiety` and `anxiety_post` (`anxiety_diff`: `anxiety` - `anxiety_post) control group respondents who chose the FEEL task each time with the respondents who chose the DESCRIBE task each time. with controls. If respondents become more anxious after choosing the empathy task then we should see that their `anxiety_diff` values should be higher than their colleagues who chose the objective task each time. **no evidence found for this**
- (2) `anxiety_diff` for respondents who received `PraiseEmpathy` and then chose FEEL with respondents who received `Control` and then chose FEEL. with controls. If respondents alleviate anxiety of empathy through peer praise, we should see the first group have higher `anxiety_diff` values compared to the second group (starting values of anxiety higher than ending values).

Create SI Table B.11 Change in anxiety after choosing Empathy over Objective.
```{r}
#create additional dataset for respondents who answered FEEL in task1 AND in the real task
only_feel <- subset(data3B, #describeORfeel1==1 & 
                      describeORfeel2==1)
#respondents who answered FEEL in the real task
only_feelreal<-subset(data3B, describeORfeel2==1)
#respondents who answered DESCRIBE in the real task
only_describereal<-subset(data3B, describeORfeel2==0)
#respondents in only control for the real task
only_control <- subset(data3B, PraiseEmpathy16==0)
only_control$AlwaysChooseFeel<-ifelse(only_control$describeORfeel1==1&only_control$describeORfeel2==1,1,0)
only_control$AlwaysChooseDescribe<-ifelse(only_control$describeORfeel1==0&only_control$describeORfeel2==0,1,0)
only_control$AlwaysChooseFeel_vs_AlwaysChooseDescribe<-ifelse(only_control$AlwaysChooseFeel==1,1,ifelse(only_control$AlwaysChooseDescribe==1,0,NA))

## (1)
## do people become more anxious after choosing empathy? compare people in the control group (never received praise) who choose feel always against people in control group who choose describe always and see if anxiety higher in the former group. observational so control for gender, age, educ, race, party.
anx1<-lm(anxiety_diff ~ AlwaysChooseFeel_vs_AlwaysChooseDescribe + Sex + Age + Education + Race + Party, data = only_control)
coeftest(anx1, vcov = vcovHC, type = "HC1")
anx1_2<-lm(anxiety_post ~ anxiety + AlwaysChooseFeel_vs_AlwaysChooseDescribe + Sex + Age + Education + Race + Party, data = only_control)
#coeftest(anx1_2, vcov = vcovHC, type = "HC1")
#doesn't seem like people get more anxious if they choose empathy vs objective

latex_table<-data.frame(Coefficient=c("Intercept","Choose Empathy over Objective")
              ,Estimate=round(c(coeftest(anx1, vcov = vcovHC, type = "HC1")[1,1],coeftest(anx1, vcov =vcovHC,type= "HC1")[2,1]),4)
              ,SE=round(c(coeftest(anx1, vcov = vcovHC, type = "HC1")[1,2],coeftest(anx1, vcov =vcovHC,type= "HC1")[2,2]),4)
              ,p=round(c(coeftest(anx1, vcov = vcovHC, type = "HC1")[1,4],coeftest(anx1, vcov =vcovHC,type= "HC1")[2,4]),4))

#LaTeX table
kable(latex_table, booktabs = T, caption = "Change in anxiety after choosing Empathy over Objective. OLS regression of Change in anxiety regressed on choosing Empathy Objective controlling for sex, age, education, race and party. Coefficient of interest is regression coefficient test for Choose Empathy.",label="anxiety1" ,"latex"
      ,col.names = c("","Estimate","s.e.","p"))%>% 
  kable_styling(latex_options = c("striped", "scale_down"),position = "center",font_size=12)%>%#, "scale_down"
  row_spec(0, bold = T) %>%
  column_spec(1, bold = T, color = "black", width="4cm") %>%
  column_spec(2, width = "2cm")%>% #est
  column_spec(3, width = "2cm")%>% #se
  column_spec(4, width = "2cm") #p

```

To see if respondents alleviate anxiety of empathy through peer praise, we further explored changes in reported anxiety among respondents who received either peer praise for empathy or control and who only chose the empathy task (comparing treatment effects on changes in anxiety while holding the task chosen constant). If it were the case that peer praise alleviates anxiety around the empathy task, we should see the peer praised group report higher changes in anxiety values compared to the second control. Again, this is an observational exploration, so we control for respondent sex, age, education, race and party. 

Create SI Table B.12: Change in anxiety after peer praise for empathy.

```{r}
## (2)
## `anxiety_diff` for respondents who received `PraiseEmpathy` and then chose FEEL with respondents who received `Control` and then chose FEEL. with controls. If respondents alleviate anxiety of empathy through peer praise, we should see the first group have higher `anxiety_diff` values compared to the second group (starting values of anxiety higher than ending values). with controls.
anx2<-lm(anxiety_diff ~ PraiseEmpathy16 + Sex + Age + Education + Race + Party, data = only_feel)
coeftest(anx2, vcov = vcovHC, type = "HC1")
# no evidence of this at work

latex_table2<-data.frame(Coefficient=c("Intercept","Peer praise")
              ,Estimate=round(c(coeftest(anx2, vcov = vcovHC, type = "HC1")[1,1],coeftest(anx2, vcov =vcovHC,type= "HC1")[2,1]),4)
              ,SE=round(c(coeftest(anx2, vcov = vcovHC, type = "HC1")[1,2],coeftest(anx2, vcov =vcovHC,type= "HC1")[2,2]),4)
              ,p=round(c(coeftest(anx2, vcov = vcovHC, type = "HC1")[1,4],coeftest(anx2, vcov =vcovHC,type= "HC1")[2,4]),4))

#LaTeX table
kable(latex_table2, booktabs = T, caption = "Change in anxiety after peer praise for empathy. OLS regression of Change in anxiety regressed on Peer Praise controlling for sex, age, education, race and party. Coefficient of interest is regression coefficient test for Peer praise.",label="anxiety2" ,"latex"
      ,col.names = c("","Estimate","s.e.","p"))%>% 
  kable_styling(latex_options = c("striped", "scale_down"),position = "center",font_size=12)%>%#, "scale_down"
  row_spec(0, bold = T) %>%
  column_spec(1, bold = T, color = "black", width="4cm") %>%
  column_spec(2, width = "2cm")%>% #est
  column_spec(3, width = "2cm")%>% #se
  column_spec(4, width = "2cm") #p
```





# Study 4
## Study 4 covariate summary table

Information to create SI Table B.13:

```{r sumcovariates4}
#Latex Table of Covariates for Study 4:
#covariate table part 1
kable(summarize(data4, type = "factor", variables = c( "Sex",
                                                      "Party", "Ideology",
                                                      "Race","Education", 
                                                      "Income", "Religion"
                                                     ))
    ,caption="Study 4 Respondents"
    ,booktabs=TRUE,"latex",longtable=FALSE) %>% kable_styling(latex_options = c("striped", "hold_position","repeat_header")) 
#covariate table part 2
data4$Age<-as.numeric(data4$age)
kable(summarize(data4, type = "numeric", variables = "Age"),booktabs=TRUE,"latex",longtable=FALSE) %>% kable_styling(latex_options = c("striped", "hold_position","repeat_header")) 
#combine covariate tables 1 and 2, then add in caption: "\bf Study 4 Respondents (Summarizing covariates)}. Total number of respondents 223. "
#may need to adjust LaTeX font of table to scriptsize; adjust Missing text
```

Other notes that appear in the main text:

```{r otherstats4}
#mean, range of age
summary(as.numeric(data4$age))
#sd age
sd(as.numeric(data4$age),na.rm=TRUE)
#percent gender
prop.table(table(data4$Sex,useNA='always'))
#percent race
prop.table(table(data4$Race,useNA='always'))
#percent education
prop.table(table(data4$Education,useNA='always'))

#happy: to calculate "more than a one third standard deviation increase in happiness", take coefficient on peer praise for happiness in Study 4 0.4175/sd(data4$happy,na.rm=T)
summary(data4$happy)
sd(data4$happy,na.rm=T)
```

## Study 4 Attrition

Information to create SI Figure B.14: Attrition across survey questions.

```{r attrition-s4 data}
#select relevant questions, only for arms we study in the manuscript for this study: "control-happiness","empathetic","objective"
attrite4<- data4[, c("consent", "age","sex","education","state",
                     "attention1",#"attention_grid",
                       "cards_a", "pa", "pb_1", "pb_2", "pb_3", "pc", 
                       "cards_b", "p2a", "p2b_1", "p2b_2", "p2b_3", "p2c",
                     "treat16",#treatment arm
                       "happy",#mediator
                     "cards1",#outcome
                      "post1", "post2_4", "post3",
                    "post4", "post5", "post6", "post7", 
                    "post8", "post9", "post10",
                    "post11_1","post11_2","post11_3","post11_4",
                    "post11_5","post11_6","post11_7","post11_8",
                    "post13_1", "post14_1", "post15_1", "post16_1", "post17", 
                    "race","income","religion","part_id",
                    "ideology","pres_approval"
                    )] #, "donation")]
attrite4<-subset(attrite4,treat16=="happiness"|treat16=="empathetic"|treat16=="objective")
#create attrition dataset
#attrition_dataset<-attrition(data = attrite3)


plot_attrition(data = attrite4
               ,treatment = c("treat16") 
               ,pre_treatment = c("cards_a", "cards_b") #practice round
               ,DV = c(paste("cards",1:15,sep=""),"task") #choice of deck main task, then task for real wage task.
               ,mediator = "happy"
               ,freq = FALSE
               )   + ylim(0,1)
ggsave("Figures/attrition_4.png",  width = 11, height = 6)
#Figures/attrition_4.pdf 11x6

attrition(attrite4)#11/223
```

## Study 4 Pride

Information to create SI Figure B.15: Pride of respondents in peer praise (for empathy) and control groups. 

```{r praisepride}
praisepride1 <- lm(pride ~ PraiseEmpathy, data = data4)
summary(praisepride1)
confint(praisepride1)

data4 %>%
  ggplot( aes(x=pride, fill=as.factor(PraiseEmpathy))) +
    geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
    scale_fill_manual(values=c("#69b3a2", "#404080")) +
    theme_ipsum() +
    labs(fill="")
#t.test(data4$pride~data4$PraiseEmpathy)
# sample size
sample_size = data4 %>% filter(!is.na(PraiseEmpathy))%>% group_by(PraiseEmpathy) %>% dplyr::summarize(num=n())
data4$name<-ifelse(data4$PraiseEmpathy==1,"Peer praise empathy",ifelse(data4$PraiseEmpathy==0,"Control",""))
# Plot
praiseprideplot<-data4 %>%
  filter(!is.na(PraiseEmpathy))%>%
  left_join(sample_size) %>%
  #mutate(myaxis = paste0(name, "\n", "n=", num)) %>%
  mutate(myaxis = name) %>%
  ggplot( aes(x=myaxis, y=happy, fill=name)) +
    geom_violin(width=1) +
    geom_boxplot(width=0.1, color="grey20", alpha=0.2) +
    scale_fill_viridis(discrete = TRUE,alpha=0.7,begin=0.25,end=1,option="D") +
    theme_bw() + ylab("Pride") + xlab("") + ggtitle("Pride distribution by treatment arm") + 
    theme(
      legend.position="none",
      axis.title.y = element_text(size=12),
      axis.text.y = element_text(size=12),
      axis.text.x = element_text(size=12),
      plot.title = element_text(size=13,face="bold")
    ) + coord_flip()  + geom_text(x=2.535,y=3,label="Difference in means: 0.487 (p=0.002)",color="gray20",size=4.5)
praiseprideplot 
#praise-pride_dist.pdf 7x7
#extract data from ggplot object
plot_data <- ggplot_build(praiseprideplot)$data
#boxplot data
boxplot_data <- plot_data[[2]] %>%
  dplyr::select(x, ymin, lower, middle, upper, ymax)
#Caption: Pride of respondents in peer praise (for empathy) and control groups: difference in means (two sample t) test estimate: \myhl{(estimate=$0.487$, t=$3.113$,p=$0.002$, CI$[0.179, 0.795]$)}. Boxplot Control information: minima = 1, lower 25 = 2.33, middle = 3, upper 75 = 4, maxima = 5. Boxplot Peer praise empathy information: minima = 1.67, lower 25 = 3, middle = 3.33, upper 75 = 4.25, maxima = 5.
```


# Study 5
## Study 5A covariate summary table

Information to create SI Table B.14:

```{r sumcovariates5}
#Latex Table of Covariates for Study 5A:
#covariate table part 1
kable(summarize(data5, type = "factor", variables = c( "Sex",
                                                      "Party", "Ideology",
                                                      "Race","Education", 
                                                      "Income", "Religion"
                                                     ))
    ,caption="Study 5A Respondents"
    ,booktabs=TRUE,"latex",longtable=FALSE) %>% kable_styling(latex_options = c("striped", "hold_position","repeat_header"))
#covariate table part 2
data5$Age<-as.numeric(data5$age)
kable(summarize(data5, type = "numeric", variables = "Age"),booktabs=TRUE,"latex",longtable=FALSE) %>% kable_styling(latex_options = c("striped", "hold_position","repeat_header"))
#combine covariate tables 1 and 2, then add in caption: "\bf Study 5A Respondents (Summarizing covariates)}. Total number of respondents 337."
#may need to adjust LaTeX font of table to scriptsize; adjust Missing text
```

Other notes that appear in the main text:

```{r otherstats5}
#mean, range of age
summary(as.numeric(data5$age))
# There is a person who reported their age was 10; also missed attention checks; data5$attention[63] so drop from analysis. 
#sd age
sd(as.numeric(data5$age),na.rm=TRUE)
#percent gender
prop.table(table(data5$Sex,useNA='always'))
#percent race
prop.table(table(data5$Race,useNA='always'))
#percent education
prop.table(table(data5$Education,useNA='always'))

#happy: 
summary(data5$happy)
sd(data5$happy,na.rm=T)
```


## Study 5B covariate summary table

Information to create SI Table B.15:

```{r sumcovariates6}
#Latex Table of Covariates for Study 5B:
#covariate table part 1
kable(summarize(data6, type = "factor", variables = c( "Sex",
                                                      "Party", "Ideology",
                                                      "Race","Education", 
                                                      "Income", "Religion"
                                                     ))
    ,caption="Study 5B Respondents"
    ,booktabs=TRUE,"latex",longtable=FALSE) %>% kable_styling(latex_options = c("striped", "hold_position","repeat_header"))%>%
  save_kable(file = here::here("Figures/Table_S13a.png"))
#covariate table part 2
data6$Age<-as.numeric(data6$age)
kable(summarize(data6, type = "numeric", variables = "Age"),booktabs=TRUE,"latex",longtable=FALSE) %>% kable_styling(latex_options = c("striped", "hold_position","repeat_header"))
#combine covariate tables 1 and 2, then add in caption: "\bf Study 5B Respondents (Summarizing covariates)}. Total number of respondents 624. "
#may need to adjust LaTeX font of table to scriptsize; adjust Missing text
```

```{r otherstats6}
#mean, range of age
summary(as.numeric(data6$age))
#sd age
sd(as.numeric(data6$age),na.rm=TRUE)
#percent gender
prop.table(table(data6$Sex,useNA='always'))
#percent race
prop.table(table(data6$Race,useNA='always'))
#percent education
prop.table(table(data6$Education,useNA='always'))

#happy: 
summary(data6$happy)
sd(data5$happy,na.rm=T)
```

## Study 5A Attrition

Create SI Figure B.17: Study 5A Attrition across survey questions

```{r attrition-s5a data}
#select relevant questions, only for arms we study in the manuscript for this study: "control-happiness","empathetic","objective"
attrite5A<- data5[, c("consent", "age","sex","education","state","income","part_id","race","religion",
                     "attention",
                       "cards_a", "pa", "pb_1", "pb_2", "pb_3", "pc", 
                       "cards_b", "p2a", "p2b_1", "p2b_2", "p2b_3", "p2c",
                     "treat1","happy_1","cards1",#treatment,#mediator,#outcome
                     "treat2","happy_2","cards2",
                     "treat3","happy_3","cards3","treat4","happy_4","cards4",
                     "treat5","happy_5","cards5","treat6","happy_6","cards6",
                     "treat7","happy_7","cards7","treat8","happy_8","cards8",
                     "treat9","happy_9","cards9","treat10","happy_10","cards10",
                     "treat11","happy_11","cards11","treat12","happy_12","cards12",
                     "treat13","happy_13","cards13","treat14","happy_14","cards14",
                     "treat15","happy_15","cards15","treat16","happy_16","cards16",
                     "treat17","happy_17","cards17","treat18","happy_18","cards18",
                     "treat19","happy_19","cards19","treat20","happy_20","cards20",
                      "post1", "post2_7", "post3",
                    "post4", "post5", "post6", "post7", 
                    "post8", "post9", "post10",
                    "post11_1","post11_2","post11_3","post11_4",
                    "post11_5","post11_6","post11_7","post11_8",
                    "post13_1", "post14_1", "post15_1", "post16_1", "post17", 
                    "Ideology",
                    "trump_approval","pres_approval"
                    )]

plot_attrition(data = attrite5A
               ,treatment = c(paste("treat",1:20,sep="")) 
               ,pre_treatment = c("cards_a", "cards_b") #practice round
               ,DV = c(paste("cards",1:20,sep="")) #choice of deck main task
               ,mediator = c(paste("happy_",1:20,sep=""))
               ,freq = FALSE
               )   + ylim(0,1)
ggsave("Figures/attrition_5A.png",  width = 11, height = 6)
#Figures/attrition_5A.pdf 11x6
#Caption: \textbf{Study 5A: Attrition across survey questions:} X axis denotes survey questions in chronological order. Orange vertical lines mark pre-treatment practice rounds of behavioral empathy tasks. Red vertical line marks peer praise treatment. Green vertical line marks the Discrete Emotions Questionnaire questions on happiness. Blue vertical line marks outcome questions: open-ended, three short words, and a feeling thermometer, which followed the behavioral empathy tasks. Y axis is the proportion of total n attrited, calculated as number of attrited respondents / total n.
```


## Study 5B Attrition

Create SI Figure B.18: Study 5B Attrition across survey questions

```{r attrition-s5b data}
#select relevant questions, only for arms we study in the manuscript for this study: "control-happiness","empathetic","objective"
attrite5B<- data6[, c("consent", "age","sex","education","state","income","part_id","race","religion",
                     "attention",
                       "cards_a", "pa", "pb_1", "pb_2", "pb_3", "pc", 
                       "cards_b", "p2a", "p2b_1", "p2b_2", "p2b_3", "p2c",
                     "treat1","happy_1","cards1",#treatment,#mediator,#outcome
                     "treat2","happy_2","cards2",
                     "treat3","happy_3","cards3",
                      "post1", "post2_7", "post3",
                    "post4", "post5", "post6", "post7", 
                    "post8", "post9", "post10",
                    "post11_1","post11_2","post11_3","post11_4",
                    "post11_5","post11_6","post11_7","post11_8",
                    "post13_1", "post14_1", "post15_1", "post16_1", "post17", 
                    "Ideology",
                    "trump_approval","pres_approval"
                    )]

plot_attrition(data = attrite5B ,treatment = c(paste("treat",1:3,sep="")) ,pre_treatment = c("cards_a", "cards_b") ,DV = c(paste("cards",1:3,sep="")) ,other_group = "Happy mediator" ,other_group_var = c(paste("happy_",1:3,sep="")) ,freq = FALSE )+ ylim(0,1)
ggsave("Figures/attrition_5B.png",  width = 11, height = 6)
#Figures/attrition_5B.pdf 11x6
```


## Study 5 Mediation sensitivity analysis

### Sensitivity analysis for Sequential Ignorability Assumption

We analyze the mediating effect of happiness on the choice task variable using Imai et al. 2010 approach for model-based causal mediation analysis; the key assumption required is sequential ignorability.

Specify 2 statistical models:
1) mediator model for the conditional distribution of the mediator $M_i$ given treatment $T_i$ and a set of the observed pre-treatment covariates $X_i$ and 
2) outcome model for the conditional distribution of the outcome $Y_i|T_i,M_i,X_i$T

Fit 1) and 2) separately. The fitted objects are main inputs to the `mediate` fn, which computes the estimated ACME and other quantities of interest under these models and the sequential ignorability assumption.

We're going to control for X. All confidence interval estimators are estimated with clustered standard errors at the respondent ID level.

* Conduct a sensitivity analysis for the possible existence of unobserved pre-treatment covariates.
* Sensitivity parameter $\rho\equiv \text{Corr}(\epsilon_{i2},\epsilon_{i3})$; sequential ignorability implies $\rho=0$. We set $\rho$ at different values and see how our ACME changes.
* Studies 5A+5B->pooled

```{r sensitivityestim, eval=FALSE}
## medsens seems to have trouble (can't estimate logit link), and probit link doesn't have an easy pull of the Mmodel.var.cov from out object so using lpm 
set.seed(32021)
nsims=1000


##combined
happy_med <- lm(happy ~ PraiseEmpathy, data=long_datapool)
happy_out <- lm(describeORfeel~PraiseEmpathy + happy, data = long_datapool)#, family=binomial(link="probit"))

#note that we cannot run boot=TRUE with clustering
mediation_happytot_lm <-  mediate(happy_med, happy_out, treat = "PraiseEmpathy", mediator = "happy", boot=FALSE, conf.level=.95, sims=nsims,cluster=long_datapool$ID)
saveRDS(mediation_happytot_lm, file=here::here("mediation_happytot_lm.rds"))

mediation_happytot_lm<-readRDS(file="mediation_happytot_lm.rds")
sens_outtot <- medsens(mediation_happytot_lm, rho.by = 0.01, effect.type = "indirect", sims = nsims)#vary rho values to
saveRDS(sens_outtot,file=here::here("sens_outtot.rds"))
```


```{r sensitivity-analysis}
sens_outtot<-readRDS(file="sens_outtot.rds")
summary(sens_outtot)
```

For Pooled $\rho$ = 0.12 then ACME becomes 0.

We interpret sensitivity with $R^2$s below. Assume the standard estimation models for Mediator/Outcome:

$Y_i=\alpha_1 + \beta_1 T_i + \epsilon_{i1}$
$M_i=\alpha_2 + \beta_2 T_i + \epsilon_{i2}$
$Y_i=\alpha_3 + \beta_3 T_i + \gamma M_i + \epsilon_{i3}$

Assume the unobserved (pre-treatment) confounder formulation

$\epsilon_{i2} = \lambda_2 U_i + \epsilon'_{i2}$
and
$\epsilon_{i3} = \lambda_3 U_i + \epsilon'_{i3}$

How much does $U_i$ have to explain for our results to go away?

Create SI Figure B.19: Proportion of original variance explained by $U_i$:

```{r sensitivity-plot}
plot(sens_outtot, sens.par = "rho", main = "Sensitivity Analysis (5 pooled)", ylim = c(-0.2, 0.2),xlim=c(-0.5,0.5))
#caption: {\bf Proportion of original variance explained by $U_i$.} 95\% confidence intervals plotted. 
#Figures/sensitivity-rhotot.pdf 6x6
```

The last plot is plotting the proportion of original variance explained by $U_i$:

$\tilde{R}^2_M \equiv \frac{var(\epsilon_{i2}) - var(\epsilon'_{i2})}{var(M_i)}$
and
$\tilde{R}^2_Y \equiv \frac{var(\epsilon_{i3}) - var(\epsilon'_{i3})}{var(Y_i)}$

Reparameterize $\rho$ using $(\tilde{R}^2_M,\tilde{R}^2_Y)$:
$\rho = \frac{\text{sgn}(\lambda_2\lambda_3)\tilde{R}_M\tilde{R}_Y}{\sqrt{(1-\tilde{R}^2_M)(1-\tilde{R}^2_Y)}}$
where $R^2_M$ and $R^2_Y$ are from the original mediator/outcome models. We can set $(\tilde{R}^2_M,\tilde{R}^2_Y)$ to different values and see how mediation effects change.

The plot below assumes that the confounder influences both the mediator and outcome variables in the same direction. (This matters because the sensitivity analysis is in terms of the product of $R^2$ statistics; I'm assuming positive because it seems more likely that something positively affecting the Mediator and the Outcome is happening to create the positive finding for the ACME). The bold line represents the various combinations of $R^2$ statistics where the ACME would be 0. In this case the product would have to be 0.014 for the ACME to become 0. Another way to say this is that when the product of the original variance explained by the omitted confounding is 0.014, the point estimate for ACME would be 0.

Create SI Figure B.20: $R^2$ statistics for which ACME would be 0.


```{r sensitivity-plot-confound}
plot(sens_outtot, sens.par = "R2", r.type = "total", main = "Sensitivity Analysis (5 pooled)", ylim = c(0,.9),xlim=c(0,1),
     sign.prod="positive",
     xlab="Proportion of Total Variance in Happy\n Explained by Confounder",
     ylab="Proportion of Total Variance in choosing empathy task\n Explained by Confounder") # assume confounder influences both mediator/outcome variables in same direction
#Figures/sensitivity-confoundtot.pdf 6x6
```


# Study 6

Peer praise and empathy: *Outgroup bias reduced through peer praise*: We hypothesize that (white) respondents who receive peer praise are more likely to choose to empathize with black individuals than respondents who do not receive peer praise and see black individuals.

## Study 6 covariate summary tables
Information to create SI Figures B.22 and B.23: 

```{r sumcovariates6PE}
## SI Figure B.22
#All respondents who pass attention checks and first trial they do
data6PE_2<-subset(long_data6PE,trial_no==1&attention==2)
## SI Figure B.23
#Latex Table of Covariates for Study 6:
#1) whites, see black images, who pass attention checks and the first trial they do
data6PE_1<-subset(long_data6PE,Race=="White, not-Hispanic"&race_randomized=="B"&trial_no==1&attention==2)

#covariate table
kable(summarize(data6PE_1, type = "factor", variables = c( "Sex",
                                                      "Party", "Ideology",
                                                      "Race","Education", 
                                                      "Income", "Religion"
                                                     ))
    ,caption="Study 6 Respondents"
    ,booktabs=TRUE,"latex",longtable=FALSE) %>% kable_styling(latex_options = c("striped", "hold_position","repeat_header")) #save as: desc2_study6.png
#Caption: "\bf Study 6 Respondents (Summarizing covariates)} white respondents who saw Black images (Summarizing covariates, N=218). "
#may need to adjust LaTeX font of table to scriptsize; adjust Missing text
```
 

## Study 6 peer praise effect on outgroup bias

```{r}
#Model
#1) whites, see black images, who pass attention checks and the first trial they do
model1_1<- glm(describeORfeel~PraiseEmpathy,data=data6PE_1,family=binomial(link="logit"))
summary(model1_1)#N=218

# Put model estimates into temporary data.frames:
main_variable_names<-c("Control","Peer Praise")
model1Frame <- data.frame(Variable = main_variable_names,
                          Coefficient = coef(model1_1),
                          SE = summary(model1_1)$coefficients[, 2],
                          modelName = "Main model")

# Specify the width of your confidence intervals
interval1 <- -qnorm((1-0.9)/2)  # 90% multiplier
interval2 <- -qnorm((1-0.95)/2)  # 95% multiplier

h1plot <- model1Frame %>%
  ggplot(aes(colour = modelName, group=modelName)) + scale_color_viridis(begin=0.5,end=0,option="D",discrete=T) + geom_hline(yintercept = 0, colour = gray(1/2), lty = 2) + ylab("Log odds coefficient for FEEL") + xlab("") + 
  geom_linerange(aes(x = Variable, ymin = Coefficient - SE*interval1, ymax = Coefficient + SE*interval1), lwd = 1.25, position = position_dodge(width = 1/2)) +
  geom_pointrange(aes(x = Variable, y = Coefficient, ymin = Coefficient - SE*interval2, ymax = Coefficient + SE*interval2, fill=modelName), lwd = 0.75, position = position_dodge(width = 1/2),shape = 21) + scale_fill_viridis(begin=0.5,end=0,option="D",discrete=T) + coord_flip() + theme_bw() +  theme(legend.position = "none") + ggtitle("Peer praise effect on outgroup bias")
print(h1plot)

ggsave(h1plot,file=here::here("Figures","mainfig_study6.pdf"),width=9,height=6)
#caption: \textbf{Pilot Study 6 main effect: Peer-praise effect on outgroup bias for attentive white respondents, trial 1.} Points plotted at the center of bands are logistic regression coefficients of control (intercept = -1.073) and Peer Praise (=0.756) of choosing empathy for the outgroup regressed on Peer Praise (N=218). Bands are (thick) 90\% and (thin) 95\% confidence intervals. The baseline odds of choosing FEEL over DESCRIBE is 0.34 times; the odds of choosing FEEL over DESCRIBE if respondents are in the treatment group is 2.13 (p=0.01; 203 degrees of freedom;\myhl{ 95\% CI [1.18, 3.89]}) compared to the control group.
```

# Study 7


## Study 7 covariate table

Create SI Table B.16 Study 7 respondents:

```{r}

kable(summarize(data7, type = "factor", variables = c( "Gender",
                                                      "Party",
                                                      "Race","Education"
                                                     ))
    ,caption="Study 7 Respondents"
    ,booktabs=TRUE,"latex",longtable=FALSE) 
#Caption: "\bf Study 7 Respondents (Summarizing covariates)}. N=590. "
#may need to adjust LaTeX font of table to scriptsize; adjust Missing text
```


## Study 7 main effect plot

Create SI Figure B.25 Pilot Study 7 main effect:
```{r}
#we compare respondents who received co-partisan praise (meaning respondents who identify as Democrats and received praise from Democrats and respondents who identify as Republicans and received praise from Republicans, n=110), to respondents in the general praise control (n=198). We regress our co-partisan peer praise treatment over two outcomes of interest: (1) choice of "FEEL" in our behavioral empathy task, and (2) choosing to be redirected to the BLM page at the end of the survey.

model1a<-lm_robust(describeORfeel~CoParty_control,data7)%>% tidy %>% 
  mutate(.,
         outcome = "Choice Task",
         Sample = "Full")  #nobs(lm_robust(describeORfeel~CoParty_control,data7)) = 267

model1b<-lm_robust(describeORfeel~CoParty_control,data7_attentive)%>% tidy %>% 
  mutate(.,
         outcome = "Choice Task",
         Sample = "Attentive") #nobs(lm_robust(describeORfeel~CoParty_control,data7_attentive))=100

model2a<-lm_robust(BLM~CoParty_control,data7)%>% tidy %>% 
  mutate(.,
         outcome = "BLM",
         Sample = "Full") #nobs(lm_robust(BLM~CoParty_control,data7))=249

model2b<-lm_robust(BLM~CoParty_control,data7_attentive)%>% tidy %>% 
  mutate(.,
         outcome = "BLM",
         Sample = "Attentive") #nobs(lm_robust(BLM~CoParty_control,data7_attentive))=94

main_fx <- rbind(model1a,model1b,model2a,model2b) %>% 
  filter(.,
         term == "CoParty_control")


order_x <- c("Choice Task", "BLM")

# Generate coefficient plot 
ggplot(main_fx, aes(x = outcome, y = estimate, color = Sample, shape = Sample)) +
  geom_hline(yintercept = 0, color = "gray50", linetype = 2, size = 0.2) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high),
                  position = position_dodge(width = 0.4)) +
  #coord_flip()+
  labs(x = "",
       y = "Effect Size of Co-Partisan Praise") +
  scale_x_discrete(limits= order_x) + 
  scale_color_manual(values = c("firebrick2","dodgerblue2")) +
  scale_fill_manual(values = c("firebrick2","dodgerblue2")) +
  theme(text = element_text(size = 10, family = "Times"),
        legend.key=element_blank(),
        panel.grid.major = element_blank(), 
        axis.text.x = element_text(size = 10),
        plot.caption = element_text(size = 10, family = "Times",hjust = -.02),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black"))

ggsave(file=here::here("Figures","partypraise-on-empathy-blm.pdf"),width=8,height=6)

#Caption:\textbf{Pilot Study 7 main effect: Peer-praise effect on behavioral empathy task (choice task) and semi-behavioral outcome (BLM).} Points plotted at the center of bands are OLS regression coefficients of dependent variable regressed on Co-Partisan Praise with robust standard errors. Full sample model for Choice task has N=267; for BLM N=249. Attentive sample models for Choice task has N=100; for BLM N=94. Bands are 95\% confidence intervals.
```

# Scope of peer praise for empathy

Estimated standard errors are clustered at respondent levels and robust, and 90 and 95\% confidence intervals are plotted throughout.

We conduct subgroup analyses drawing on data from Pilots 3, 5, and 6 (details of data used for each analysis in captions of each graphic).


* Uses Study 3 T->Y (`long_data3`)
* Study 5/6 T-M-Y (pooled: `long_datapool`)
* Study 3+5+6 T-M-Y (total pooled: `long_datatotpool`)
* Notes: presidential approval question for Study 3 was for Donald Trump. Studies 5 and 5 asked about approval for Trump again but then presidential approval was also asked for Joe Biden (who was in office by this time).
* 1 is approve extremely strongly 7 is disapprove extremely strongly -- reorder so reverse

```{r scopedata}
#set up data for scope section
#study 3: presidential(trump) approval variable
long_data3$trump_approval_n<-ifelse(long_data3$pres_approval=="1",7
                                ,ifelse(long_data3$pres_approval=="2",6
                                    ,ifelse(long_data3$pres_approval=="3",5
                                        ,ifelse(long_data3$pres_approval=="4",4
                                            ,ifelse(long_data3$pres_approval=="5",3
                                               ,ifelse(long_data3$pres_approval=="6",2
                                                  ,ifelse(long_data3$pres_approval=="7",1,NA)))))))
#5/6
#presidential(trump) approval variable: trump_approval
#presidential(biden) approval variable: pres_approval
long_data5_new$trump_approval_n<-ifelse(long_data5_new$trump_approval=="1",7
                                ,ifelse(long_data5_new$trump_approval=="2",6
                                    ,ifelse(long_data5_new$trump_approval=="3",5
                                        ,ifelse(long_data5_new$trump_approval=="4",4
                                            ,ifelse(long_data5_new$trump_approval=="5",3
                                               ,ifelse(long_data5_new$trump_approval=="6",2
                                                  ,ifelse(long_data5_new$trump_approval=="7",1,NA)))))))
long_data6_new$trump_approval_n<-ifelse(long_data6_new$trump_approval=="1",7
                                ,ifelse(long_data6_new$trump_approval=="2",6
                                    ,ifelse(long_data6_new$trump_approval=="3",5
                                        ,ifelse(long_data6_new$trump_approval=="4",4
                                            ,ifelse(long_data6_new$trump_approval=="5",3
                                               ,ifelse(long_data6_new$trump_approval=="6",2
                                                  ,ifelse(long_data6_new$trump_approval=="7",1,NA)))))))
long_data5_new$biden_approval_n<-ifelse(long_data5_new$pres_approval=="1",7
                                ,ifelse(long_data5_new$pres_approval=="2",6
                                    ,ifelse(long_data5_new$pres_approval=="3",5
                                        ,ifelse(long_data5_new$pres_approval=="4",4
                                            ,ifelse(long_data5_new$pres_approval=="5",3
                                               ,ifelse(long_data5_new$pres_approval=="6",2
                                                  ,ifelse(long_data5_new$pres_approval=="7",1,NA)))))))
long_data6_new$biden_approval_n<-ifelse(long_data6_new$pres_approval=="1",7
                                ,ifelse(long_data6_new$pres_approval=="2",6
                                    ,ifelse(long_data6_new$pres_approval=="3",5
                                        ,ifelse(long_data6_new$pres_approval=="4",4
                                            ,ifelse(long_data6_new$pres_approval=="5",3
                                               ,ifelse(long_data6_new$pres_approval=="6",2
                                                  ,ifelse(long_data6_new$pres_approval=="7",1,NA)))))))
#Study 3 base empathy battery index
long_data3$BaseEmpathy_battery <- long_data3$BaseEmpathy_perspective + long_data3$BaseEmpathy_warm + long_data3$BaseEmpathy_anxiety + long_data3$BaseEmpathy_imagination
# Find tertiles
vTert = quantile(long_data3$BaseEmpathy_battery, c(0:3/3),na.rm=TRUE)
# classify values
long_data3$BaseEmpathy_tercile <-  with(long_data3,cut(BaseEmpathy_battery,vTert,include.lowest = T,labels = c("Low", "Medium", "High")))

#Study 5 base empathy battery index
long_data5_new$BaseEmpathy_battery <- long_data5_new$BaseEmpathy_perspective + long_data5_new$BaseEmpathy_warm + long_data5_new$BaseEmpathy_anxiety + long_data5_new$BaseEmpathy_imagination
#Study 6 base empathy battery index
long_data6_new$BaseEmpathy_battery <- long_data6_new$BaseEmpathy_perspective + long_data6_new$BaseEmpathy_warm + long_data6_new$BaseEmpathy_anxiety + long_data6_new$BaseEmpathy_imagination

long_datapool<-data.frame(ID=c(long_data5_new$ID_pool,long_data6_new$ID_pool)
           ,describeORfeel=c(long_data5_new$describeORfeel,long_data6_new$describeORfeel)
           ,happy=c(long_data5_new$happy,long_data6_new$happy)
           ,Party=c(as.character(long_data5_new$Party),as.character(long_data6_new$Party))
           ,Race=c(as.character(long_data5_new$Race),as.character(long_data6_new$Race))
           ,Sex=c(as.character(long_data5_new$Sex),as.character(long_data6_new$Sex))
           ,Education=c(as.character(long_data5_new$Education),as.character(long_data6_new$Education))
           ,Income=c(as.character(long_data5_new$Income),as.character(long_data6_new$Income))
           ,Age=c(as.character(long_data5_new$Age),as.character(long_data6_new$Age))
           ,trump_approval_n=c(long_data5_new$trump_approval_n,long_data6_new$trump_approval_n)
           ,biden_approval_n=c(long_data5_new$biden_approval_n,long_data6_new$biden_approval_n)
           ,BaseEmpathy_perspective=c(long_data5_new$BaseEmpathy_perspective,long_data6_new$BaseEmpathy_perspective)
           ,BaseEmpathy_warm=c(long_data5_new$BaseEmpathy_warm,long_data6_new$BaseEmpathy_warm)
           ,BaseEmpathy_anxiety=c(long_data5_new$BaseEmpathy_anxiety,long_data6_new$BaseEmpathy_anxiety)
           ,BaseEmpathy_imagination=c(long_data5_new$BaseEmpathy_imagination,long_data6_new$BaseEmpathy_imagination)
           ,BaseEmpathy_battery=c(long_data5_new$BaseEmpathy_battery,long_data6_new$BaseEmpathy_battery)
           ,attention=c(long_data5_new$attention,long_data6_new$attention)
           ,PraiseEmpathy=c(long_data5_new$PraiseEmpathy,long_data6_new$PraiseEmpathy)
)
# Find tertiles
vTert = quantile(long_datapool$BaseEmpathy_battery, c(0:3/3),na.rm=TRUE)
# classify values
long_datapool$BaseEmpathy_tercile <-  with(long_datapool,cut(BaseEmpathy_battery,vTert,include.lowest = T,labels = c("Low", "Medium", "High")))
#3/5/6
  #for unique data3 ID, add 3000
  #order is 3,5,6
long_datatotpool<-data.frame(ID=c(long_data3$ID+3000,long_data5_new$ID_pool,long_data6_new$ID_pool)
           ,describeORfeel=c(long_data3$describeORfeel,long_data5_new$describeORfeel,long_data6_new$describeORfeel)
           ,happy=c(rep(NA,nrow(long_data3)),long_data5_new$happy,long_data6_new$happy) #study3 didn't measure happy
           ,Party=c(as.character(long_data3$Party),as.character(long_data5_new$Party),as.character(long_data6_new$Party))
           ,Race=c(as.character(long_data3$Race),as.character(long_data5_new$Race),as.character(long_data6_new$Race))
           ,Sex=c(as.character(long_data3$Sex),as.character(long_data5_new$Sex),as.character(long_data6_new$Sex))
           ,Education=c(as.character(long_data3$Education),as.character(long_data5_new$Education)
                        ,as.character(long_data6_new$Education))
           ,Income=c(as.character(long_data3$Income),as.character(long_data5_new$Income)
                        ,as.character(long_data6_new$Income))
           ,Age=c(as.character(long_data3$Age),as.character(long_data5_new$Age),as.character(long_data6_new$Age))
           ,trump_approval_n=c(long_data3$trump_approval_n,long_data5_new$trump_approval_n
                               ,long_data6_new$trump_approval_n)
           ,biden_approval_n=c(rep(NA,nrow(long_data3)),long_data5_new$biden_approval_n
                               ,long_data6_new$biden_approval_n)#study3 didn't measure biden
            ,BaseEmpathy_perspective=c(long_data3$BaseEmpathy_perspective
                                       ,long_data5_new$BaseEmpathy_perspective,long_data6_new$BaseEmpathy_perspective)
           ,BaseEmpathy_warm=c(long_data3$BaseEmpathy_warm,
                               long_data5_new$BaseEmpathy_warm,long_data6_new$BaseEmpathy_warm)
           ,BaseEmpathy_anxiety=c(long_data3$BaseEmpathy_anxiety,
                                  long_data5_new$BaseEmpathy_anxiety,long_data6_new$BaseEmpathy_anxiety)
           ,BaseEmpathy_imagination=c(long_data3$BaseEmpathy_imagination,
                                      long_data5_new$BaseEmpathy_imagination,long_data6_new$BaseEmpathy_imagination)
           ,BaseEmpathy_battery=c(long_data3$BaseEmpathy_battery
                                  ,long_data5_new$BaseEmpathy_battery,long_data6_new$BaseEmpathy_battery)
           ,PraiseEmpathy=c(long_data3$PraiseEmpathy,long_data5_new$PraiseEmpathy,long_data6_new$PraiseEmpathy)
)

# Find tertiles
vTert = quantile(long_datatotpool$BaseEmpathy_battery, c(0:3/3),na.rm=TRUE)
# classify values
long_datatotpool$BaseEmpathy_tercile <-  with(long_datatotpool,cut(BaseEmpathy_battery,vTert,include.lowest = T,labels = c("Low", "Medium", "High")))
```

## by Party

Create SI Figure B.26

```{r subparty}
#study 3
long_data3D<-subset(long_data3,Party=="Democrat"|Party=="Strong Democrat"|Party=="Lean Democrat")
long_data3R<-subset(long_data3,Party=="Republican"|Party=="Strong Republican"|Party=="Lean Republican")
long_data3I<-subset(long_data3,Party=="Independent"|Party=="Lean Democrat"|Party=="Lean Republican")
#models
ate3D <- miceadds::glm.cluster( data=long_data3D, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate3D) 
ate3R <- miceadds::glm.cluster( data=long_data3R, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate3R) 
ate3I <- miceadds::glm.cluster( data=long_data3I, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate3I) 
#study 5/6
long_data5D<-subset(long_datapool,Party=="Democrat"|Party=="Strong Democrat"|Party=="Lean Democrat")
long_data5R<-subset(long_datapool,Party=="Republican"|Party=="Strong Republican"|Party=="Lean Republican")
long_data5I<-subset(long_datapool,Party=="Independent")
#models
ate5D <- miceadds::glm.cluster( data=long_data5D, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate5D) 
ate5R <- miceadds::glm.cluster( data=long_data5R, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate5R) 
ate5I <- miceadds::glm.cluster( data=long_data5I, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate5I) 
#all
long_datatotD<-subset(long_datatotpool,Party=="Democrat"|Party=="Strong Democrat"|Party=="Lean Democrat")
long_datatotR<-subset(long_datatotpool,Party=="Republican"|Party=="Strong Republican"|Party=="Lean Republican")
long_datatotI<-subset(long_datatotpool,Party=="Independent")
#models
atetotD <- miceadds::glm.cluster( data=long_datatotD, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(atetotD) 
atetotR <- miceadds::glm.cluster( data=long_datatotR, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(atetotR) 
atetotI <- miceadds::glm.cluster( data=long_datatotI, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(atetotI) 

```

```{r subparty plot}

#The following are N sizes for each of the left-hand-side models, where N represents respondent-trials; n for respondents. For Study 3 Democrat, Republican, Independent models: N=1455, n=97; N=1890, n=126; N=1140, n=76. Study 5 Democrat, Republican, Independent models: N=1214, n=408; N=813, n=274; N=333, n=111. Pooled Democrat, Republican, Independent models: N=2669, n=505; N=2703, n=400; N=783, n=141.
#dim(subset(long_data3D,select=c("describeORfeel","PraiseEmpathy","ID")))
#length(unique(long_data3D$ID))
#plot data: 5, 6, pooled 
plot_data<-data.frame(group=rep(c("Study 3","Study 5A & 5B","Pooled"),each=3)
           ,type=rep(c("Democrat","Republican","Independent"),times=3)
           ,estimate=c(coef(ate3D)[2],coef(ate3R)[2],coef(ate3I)[2]
                       ,coef(ate5D)[2],coef(ate5R)[2],coef(ate5I)[2]
                       ,coef(atetotD)[2],coef(atetotR)[2],coef(atetotI)[2])
           ,se=c(summary(ate3D)[2,2],summary(ate3R)[2,2],summary(ate3I)[2,2]
                 ,summary(ate5D)[2,2],summary(ate5R)[2,2],summary(ate5I)[2,2]
                 ,summary(atetotD)[2,2],summary(atetotR)[2,2],summary(atetotI)[2,2]))
plot_data$lower=plot_data$estimate-qnorm(0.975)*plot_data$se
plot_data$upper=plot_data$estimate+qnorm(0.975)*plot_data$se
plot_data$lower90=plot_data$estimate-qnorm(0.95)*plot_data$se
plot_data$upper90=plot_data$estimate+qnorm(0.95)*plot_data$se
#plot
plot_data$type<-factor(plot_data$type,levels = c("Democrat","Republican","Independent"))
plot_data$group<-factor(plot_data$group,levels = c("Study 3","Study 5A & 5B","Pooled"))
plot_subparty<-ggplot(plot_data,aes(y=estimate,x=type,group=group)) +
  geom_pointrange(aes(ymin = lower, ymax = upper, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=0.9, linewidth=0.9) +
  geom_pointrange(aes(ymin = lower90, ymax = upper90, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=2, linewidth=2) +
  geom_hline(yintercept=0,color="gray75",linetype="dashed") +
  scale_color_viridis(#alpha=1,
                      begin=1,end=0,discrete=T,option="D",guide = guide_legend(override.aes = list(size = 0.75,
                                                                    alpha = 1) )) +
  xlab("") + ylab("Subgroup treatment effect estimate") + ylim(-0.4,0.65) + ggtitle("by Party") +
  coord_flip() + theme_bw() + 
  theme(legend.title = element_blank()
        ,axis.text.y=element_text(size=12,face="bold"))
plot_subparty


```

BaseEmpathy battery values range from 0 to 40. 

```{r subparty base empathy plot}
#to go with subparty ate plot, this plots the histogram of base empathy for each party level
#plot data: 5, 6, pooled 
plot_dataD<-data.frame(group=c(rep("Study 3",length(long_data3$BaseEmpathy_battery[which(long_data3$Party=="Democrat")]))
            ,rep("Study 5A & 5B",length(long_datapool$BaseEmpathy_battery[which(long_datapool$Party=="Democrat")]))
            ,rep("Pooled",length(long_datatotpool$BaseEmpathy_battery[which(long_datatotpool$Party=="Democrat")])))                    ,value=c(long_data3$BaseEmpathy_battery[which(long_data3$Party=="Democrat")]
                    #,long_data3$BaseEmpathy_battery[which(long_data3$Party=="Republican")]
                    #,long_data3$BaseEmpathy_battery[which(long_data3$Party=="Independent")]
                    ,long_datapool$BaseEmpathy_battery[which(long_datapool$Party=="Democrat")]
                    #,long_datapool$BaseEmpathy_battery[which(long_datapool$Party=="Republican")]
                    #,long_datapool$BaseEmpathy_battery[which(long_datapool$Party=="Independent")]
                    ,long_datatotpool$BaseEmpathy_battery[which(long_datatotpool$Party=="Democrat")]
                    #,long_datatotpool$BaseEmpathy_battery[which(long_datatotpool$Party=="Republican")]
                    #,long_datatotpool$BaseEmpathy_battery[which(long_datatotpool$Party=="Independent")]
                    ))

plot_dataR<-data.frame(group=c(rep("Study 3",length(long_data3$BaseEmpathy_battery[which(long_data3$Party=="Republican")]))
            ,rep("Study 5A & 5B",length(long_datapool$BaseEmpathy_battery[which(long_datapool$Party=="Republican")]))
            ,rep("Pooled",length(long_datatotpool$BaseEmpathy_battery[which(long_datatotpool$Party=="Republican")])))                    ,value=c(long_data3$BaseEmpathy_battery[which(long_data3$Party=="Republican")]
                    ,long_datapool$BaseEmpathy_battery[which(long_datapool$Party=="Republican")]
                    ,long_datatotpool$BaseEmpathy_battery[which(long_datatotpool$Party=="Republican")]
                    ))

plot_dataI<-data.frame(group=c(rep("Study 3",length(long_data3$BaseEmpathy_battery[which(long_data3$Party=="Independent")]))
            ,rep("Study 5A & 5B",length(long_datapool$BaseEmpathy_battery[which(long_datapool$Party=="Independent")]))
            ,rep("Pooled",length(long_datatotpool$BaseEmpathy_battery[which(long_datatotpool$Party=="Independent")])))                    ,value=c(long_data3$BaseEmpathy_battery[which(long_data3$Party=="Independent")]
                    ,long_datapool$BaseEmpathy_battery[which(long_datapool$Party=="Independent")]
                    ,long_datatotpool$BaseEmpathy_battery[which(long_datatotpool$Party=="Independent")]
                    ))
#plot
plot_data$type<-factor(plot_data$type,levels = c("Democrat","Republican","Independent"))
plot_data$group<-factor(plot_data$group,levels = c("Study 3","Study 5A & 5B","Pooled"))

plot_subempD<- ggplot(plot_dataD, aes(x=value, fill=group)) +
    geom_histogram(aes(y = ..density..),alpha=0.5,position = 'identity',bins=20) +
    scale_fill_viridis(begin=0,end=1,discrete=T,option="D"
                       ,guide = guide_legend(override.aes = list(size = 0.75, alpha = 0.5) )) +
    ylim(0,0.2) + xlab("Empathy battery") + ggtitle("Democrat")  +
    theme_bw() + 
    theme(legend.title = element_blank()
        ,axis.text.y=element_text(size=12,face="bold"))
    labs(fill="")

plot_subempR<- ggplot(plot_dataR, aes(x=value, fill=group)) +
    geom_histogram(aes(y = ..density..),alpha=0.5,position = 'identity',bins=20) +
    scale_fill_viridis(begin=0,end=1,discrete=T,option="D"
                       ,guide = guide_legend(override.aes = list(size = 0.75, alpha = 0.5) )) +
    ylim(0,0.2) + xlab("Empathy battery") + ggtitle("Republican")  +
    theme_bw() + 
    theme(legend.title = element_blank()
        ,axis.text.y=element_text(size=12,face="bold"))
    labs(fill="")

plot_subempI<- ggplot(plot_dataI, aes(x=value, fill=group)) +
    geom_histogram(aes(y = ..density..),alpha=0.5,position = 'identity',bins=20) +
    scale_fill_viridis(begin=0,end=1,discrete=T,option="D"
                       ,guide = guide_legend(override.aes = list(size = 0.75, alpha = 0.5) )) +
    ylim(0,0.2) + xlab("Empathy battery") + ggtitle("Independent")  +
    theme_bw() + 
    theme(legend.title = element_blank()
        ,axis.text.y=element_text(size=12,face="bold"))
    labs(fill="")
    
    
plot_subemp<-ggarrange(plot_subempI, plot_subempR, plot_subempD,
          ncol = 1, nrow = 3)
#ate_subpartyemp.pdf 6x6

ggarrange(plot_subparty, plot_subemp,
          ncol = 2)

ggsave(file=here::here("Figures","ate_subparty_full.pdf"),width=10,height=8)
#Caption:Left panel: Logistic regression estimated peer praise for empathy treatment effect on log likelihood of choosing empathy task, by party subgroup. Right panel: density distribution of baseline empathy battery score by party subgroup. The following are N sizes for each of the models, where N represents respondent-trials; n for respondents (n are used for right-panel density distributions). For Study 3 Democrat, Republican, Independent models: N=1455, n=97; N=1890, n=126; N=1140, n=76. Study 5 Democrat, Republican, Independent models: N=1214, n=408; N=813, n=274; N=333, n=111. Pooled Democrat, Republican, Independent models: N=2669, n=505; N=2703, n=400; N=783, n=141. Points plotted at the center of bands are logistic regression coefficients of dependent variable regressed on Peer Praise with respondent-clustered-standard-errors. Bands are 90\% and 95\% confidence intervals.
```

## by presidential approval

**Trump approval**

Create SI Figure B.27:

```{r subpresapproveTrump}
#subset data, run model, store
long_data3T<-ate3T<-long_datapoolT<-ate5T<-long_data5T<-atetotT<-long_datatotT<-vector("list",7)
estimate<-se<-matrix(NA,nrow=7,ncol=3) #rows are approval levels, cols are data source
study3_Nsize<-study5_Nsize<-pooled_Nsize<-rep(NA,7) #respondent-trial obs
study3_nsize<-study5_nsize<-pooled_nsize<-rep(NA,7) #respondent obs
for(i in 1:7){
  long_data3T[[i]]<-subset(long_data3,trump_approval_n==i)
  ate3T[[i]]<-miceadds::glm.cluster( data=long_data3T[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,1]<-coef(ate3T[[i]])[2]
  se[i,1]<-summary(ate3T[[i]])[2,2]
  temp<-subset(long_data3T[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[i]<-dim(temp)[1]
  study3_nsize[i]<-length(unique(temp$ID))
  
  long_data5T[[i]]<-subset(long_datapool,trump_approval_n==i)
  ate5T[[i]]<-miceadds::glm.cluster( data=long_data5T[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,2]<-coef(ate5T[[i]])[2]
  se[i,2]<-summary(ate5T[[i]])[2,2]
  temp<-subset(long_data5T[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[i]<-dim(temp)[1]
  study5_nsize[i]<-length(unique(temp$ID))
  
  long_datatotT[[i]]<-subset(long_datatotpool,trump_approval_n==i)
  atetotT[[i]]<-miceadds::glm.cluster( data=long_datatotT[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,3]<-coef(atetotT[[i]])[2]
  se[i,3]<-summary(atetotT[[i]])[2,2]
  temp<-subset(long_datatotT[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[i]<-dim(temp)[1]
  pooled_nsize[i]<-length(unique(temp$ID))
}



```

```{r subpresapproveTrump plot}
#plot data: 
tmp_approve_levels<-c("Disapprove extremely strongly","Disapprove moderately strongly","Disapprove slightly"
                      ,"Neither approve or disapprove","Approve slightly","Approve moderately strongly"
                      ,"Approve extremely strongly")
plot_data<-data.frame(group=rep(c("Study 3","Study 5A & 5B", "Pooled"),each=7)
           ,type=rep(tmp_approve_levels,times=3)
           ,estimate=c(estimate) #column unroll
           ,se=c(se))
plot_data$lower=plot_data$estimate-qnorm(0.975)*plot_data$se
plot_data$upper=plot_data$estimate+qnorm(0.975)*plot_data$se
plot_data$lower90=plot_data$estimate-qnorm(0.95)*plot_data$se
plot_data$upper90=plot_data$estimate+qnorm(0.95)*plot_data$se
#plot
plot_data$type<-factor(plot_data$type,levels = tmp_approve_levels)
plot_data$group<-factor(plot_data$group,levels = c("Study 3","Study 5A & 5B","Pooled"))
plot_subapproveTrump<-ggplot(plot_data,aes(y=estimate,x=type,group=group)) +
  geom_pointrange(aes(ymin = lower, ymax = upper, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=0.9,linewidth=0.9) +
  geom_pointrange(aes(ymin = lower90, ymax = upper90, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=2,linewidth=2) +
  geom_hline(yintercept=0,color="gray75",linetype="dashed") +
  scale_color_viridis(#alpha=1,
                      begin=1,end=0,discrete=T,option="D",guide = guide_legend(override.aes = list(size = 0.75,
                                                                    alpha = 1) )) +
  xlab("") + ylab("Subgroup treatment effect estimate") + ylim(-1.1,1.1) + ggtitle("by Trump approval") +
  coord_flip() + theme_bw() + 
  theme(legend.title = element_blank()
        ,axis.text.y=element_text(size=12,face="bold"))
plot_subapproveTrump
#ate_subapproveTrump.pdf 7x8
ggsave(file=here::here("Figures","ate_subapproveTrump.pdf"),width=8,height=8)

#ordering of n from disapprove to approve
#Caption:Logistic regression estimated peer praise for empathy treatment effect on log likelihood of choosing empathy task, by Trump approval subgroup. The following are N sizes for each of the models, where N represents respondent-trials; n for respondents. For Study 3 Disapprove extremely strongly down to Approve extremely strongly (N=,n=): (679,66), (189,19), (123,11), (181,19), (341,36), (567,58), (431,44). For Study 5: (717,239), (213,71), (180,60), (210,70), (380,127), (342,114), (270,90).  Pooled: (1396,305), (402,90), (303,71), (391,89), (721,163), (909,172), (701,134).  Points plotted at the center of bands are logistic regression coefficients of dependent variable regressed on Peer Praise with respondent-clustered-standard-errors. Bands are 90\% and 95\% confidence intervals.
```

**Biden approval**

Create SI Figure B.28:

* Only for 5A 5B; so just one grouping

```{r subpresapproveBiden}
#subset data, run model, store
ate5T<-long_data5T<-vector("list",7)
estimate<-se<-matrix(NA,nrow=7,ncol=1) #rows are approval levels, cols are data source
study5_Nsize<-pooled_Nsize<-rep(NA,7) #respondent-trial obs
study5_nsize<-pooled_nsize<-rep(NA,7) #respondent obs

for(i in 1:7){
  long_data5T[[i]]<-subset(long_datapool,biden_approval_n==i)
  ate5T[[i]]<-miceadds::glm.cluster( data=long_data5T[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,1]<-coef(ate5T[[i]])[2]
  se[i,1]<-summary(ate5T[[i]])[2,2]
  temp<-subset(long_data5T[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[i]<-dim(temp)[1]
  study5_nsize[i]<-length(unique(temp$ID))
}
```

```{r subpresapproveBiden plot}
#plot data: 
tmp_approve_levels<-c("Disapprove extremely strongly","Disapprove moderately strongly","Disapprove slightly"
                      ,"Neither approve or disapprove","Approve slightly","Approve moderately strongly"
                      ,"Approve extremely strongly")
plot_data<-data.frame(group=rep(c("Study 5A & 5B"),each=7)
           ,type=rep(tmp_approve_levels,times=1)
           ,estimate=c(estimate) #column unroll
           ,se=c(se))
plot_data$lower=plot_data$estimate-qnorm(0.975)*plot_data$se
plot_data$upper=plot_data$estimate+qnorm(0.975)*plot_data$se
plot_data$lower90=plot_data$estimate-qnorm(0.95)*plot_data$se
plot_data$upper90=plot_data$estimate+qnorm(0.95)*plot_data$se
#plot
plot_data$type<-factor(plot_data$type,levels = tmp_approve_levels)
plot_data$group<-factor(plot_data$group,levels = c("Study 5A & 5B"))
plot_subapproveBiden<-ggplot(plot_data,aes(y=estimate,x=type,group=group)) +
  geom_pointrange(aes(ymin = lower, ymax = upper, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=0.9, linewidth=0.9) +
  geom_pointrange(aes(ymin = lower90, ymax = upper90, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=2, linewidth=2) +
  geom_hline(yintercept=0,color="gray75",linetype="dashed") +
  scale_color_viridis(#alpha=1,
                      begin=0.5,end=0.0,discrete=T,option="D",guide = guide_legend(override.aes = list(size = 0.75,
                                                                    alpha = 1) )) +
  xlab("") + ylab("Subgroup treatment effect estimate") + ylim(-1.0,1.5) + ggtitle("by Biden approval") +
  coord_flip() + theme_bw() + 
  theme(legend.title = element_blank()
        ,axis.text.y=element_text(size=12,face="bold"))
plot_subapproveBiden
#ate_subapproveBiden.pdf 7x7
ggsave(file=here::here("Figures","ate_subapproveBiden.pdf"),width=8,height=8)



#ordering of n from disapprove to approve
#Caption:Logistic regression estimated peer praise for empathy treatment effect on log likelihood of choosing empathy task, by Biden approval subgroup. The following are N sizes for each of the models, where N represents respondent-trials; n for respondents (n are used for right-panel density distributions). Data is from Pilot 5. For Study 5 Disapprove extremely strongly down to Approve extremely strongly (N=,n=): (201,67), (105,35), (102,34), (318,106), (456,152), (692,231), (438,146). Points plotted at the center of bands are logistic regression coefficients of dependent variable regressed on Peer Praise with respondent-clustered-standard-errors. Bands are 90\% and 95\% confidence intervals.
```

## by Income
Create SI Figure B.29:

```{r subincome}
#keep track of N and n sizes in models:
study3_Nsize<-study3_nsize<-study5_Nsize<-study5_nsize<-pooled_Nsize<-pooled_nsize<-rep(NA,4)
#study 3
#levels(long_data3$Income)
long_data3100k<-subset(long_data3,Income=="100k or more")
long_data375k<-subset(long_data3,Income=="75k to less than 100k")
long_data350k<-subset(long_data3,Income=="50k to less than 75k")
long_data325k<-subset(long_data3,Income=="25k to less than 50k")
#long_data3less25k<-subset(long_data3,Income=="less than 25k") #no observations for less than 25k

#100k or more
ate3100k <- miceadds::glm.cluster( data=long_data3100k, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate3100k) 
  #n
temp<-subset(long_data3100k,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[1]<-dim(temp)[1]
  study3_nsize[1]<-length(unique(temp$ID))
  
#75k to less than 100k
ate375k <- miceadds::glm.cluster( data=long_data375k, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate375k) 
  #n
temp<-subset(long_data375k,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[2]<-dim(temp)[1]
  study3_nsize[2]<-length(unique(temp$ID))
  
#50k to less than 75k
ate350k <- miceadds::glm.cluster(data=long_data350k, formula=describeORfeel ~ PraiseEmpathy,
                                cluster="ID", family=binomial(link="logit"))
summary(ate350k) 
  #n
temp<-subset(long_data350k,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[3]<-dim(temp)[1]
  study3_nsize[3]<-length(unique(temp$ID))
  
#25k to less than 50k
ate325k <- miceadds::glm.cluster(data=long_data325k, formula=describeORfeel ~ PraiseEmpathy,
                                cluster="ID", family=binomial(link="logit"))
summary(ate325k) 
  #n
temp<-subset(long_data325k,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[4]<-dim(temp)[1]
  study3_nsize[4]<-length(unique(temp$ID))

#study 5/6
long_data5100k<-subset(long_datapool,Income=="100k or more")
long_data575k<-subset(long_datapool,Income=="75k to less than 100k")
long_data550k<-subset(long_datapool,Income=="50k to less than 75k")
long_data525k<-subset(long_datapool,Income=="25k to less than 50k")
#long_data5less25k<-subset(long_datapool,Income=="less than 25k")


#models
#100k or more
ate5100k <- miceadds::glm.cluster( data=long_data5100k, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate5100k) 
  #n
temp<-subset(long_data5100k,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[1]<-dim(temp)[1]
  study5_nsize[1]<-length(unique(temp$ID))
  
#75k to less than 100k
ate575k <- miceadds::glm.cluster( data=long_data575k, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate575k) 
  #n
temp<-subset(long_data575k,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[2]<-dim(temp)[1]
  study5_nsize[2]<-length(unique(temp$ID))
#50k to less than 75k
ate550k <- miceadds::glm.cluster(data=long_data550k, formula=describeORfeel ~ PraiseEmpathy,
                                cluster="ID", family=binomial(link="logit"))
summary(ate550k) 
  #n
temp<-subset(long_data550k,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[3]<-dim(temp)[1]
  study5_nsize[3]<-length(unique(temp$ID))
#25k to less than 50k
ate525k <- miceadds::glm.cluster(data=long_data525k, formula=describeORfeel ~ PraiseEmpathy,
                                cluster="ID", family=binomial(link="logit"))
summary(ate525k) 
  #n
temp<-subset(long_data525k,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[4]<-dim(temp)[1]
  study5_nsize[4]<-length(unique(temp$ID))


#3,5,6
long_datapool100k<-subset(long_datatotpool,Income=="100k or more")
long_datapool75k<-subset(long_datatotpool,Income=="75k to less than 100k")
long_datapool50k<-subset(long_datatotpool,Income=="50k to less than 75k")
long_datapool25k<-subset(long_datatotpool,Income=="25k to less than 50k")
#long_datapoolless25k<-subset(long_datatotpool,Income=="less than 25k")


#models
#100k or more
atepool100k <- miceadds::glm.cluster( data=long_datapool100k, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(atepool100k) 
  #n
temp<-subset(long_datapool100k,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[1]<-dim(temp)[1]
  pooled_nsize[1]<-length(unique(temp$ID))
  
#75k to less than 100k
atepool75k <- miceadds::glm.cluster( data=long_datapool75k, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(atepool75k) 
  #n
temp<-subset(long_datapool75k,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[2]<-dim(temp)[1]
  pooled_nsize[2]<-length(unique(temp$ID))
#50k to less than 75k
atepool50k <- miceadds::glm.cluster(data=long_datapool50k, formula=describeORfeel ~ PraiseEmpathy,
                                cluster="ID", family=binomial(link="logit"))
summary(atepool50k) 
  #n
temp<-subset(long_datapool50k,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[3]<-dim(temp)[1]
  pooled_nsize[3]<-length(unique(temp$ID))
#25k to less than 50k
atepool25k <- miceadds::glm.cluster(data=long_datapool25k, formula=describeORfeel ~ PraiseEmpathy,
                                cluster="ID", family=binomial(link="logit"))
summary(atepool25k) 
  #n
temp<-subset(long_datapool25k,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[4]<-dim(temp)[1]
  pooled_nsize[4]<-length(unique(temp$ID))
```

```{r subincome plot}

#plot data: 3, 5, pooled 
plot_data<-data.frame(group=rep(c("Study 3","Study 5A & 5B","Pooled"),each=4)
           ,type=rep(c("100k or more", "75k to less than 100k", "50k to less than 75k", "25k to less than 50k"),times=3)
           
           ,estimate=c(coef(ate3100k)[2],coef(ate375k)[2],coef(ate350k)[2], coef(ate325k)[2]
                       ,coef(ate5100k)[2],coef(ate575k)[2],coef(ate550k)[2], coef(ate525k)[2]
                       ,coef(atepool100k)[2],coef(atepool75k)[2],coef(atepool50k)[2],
                       coef(atepool25k)[2])
           
           ,se=c(summary(ate3100k)[2,2],summary(ate375k)[2,2],
                 summary(ate350k)[2,2],summary(ate325k)[2,2]
        
                 ,summary(ate5100k)[2,2],summary(ate575k)[2,2],
                 summary(ate550k)[2,2], summary(ate525k)[2,2]
                 
                 ,summary(atepool100k)[2,2],summary(atepool75k)[2,2],
                 summary(atepool50k)[2,2],summary(atepool25k)[2,2] ))

plot_data$lower=plot_data$estimate-qnorm(0.975)*plot_data$se
plot_data$upper=plot_data$estimate+qnorm(0.975)*plot_data$se
plot_data$lower90=plot_data$estimate-qnorm(0.95)*plot_data$se
plot_data$upper90=plot_data$estimate+qnorm(0.95)*plot_data$se
#plot
plot_data$type<-factor(plot_data$type,levels = c("100k or more", "75k to less than 100k", "50k to less than 75k", "25k to less than 50k"))
plot_data$group<-factor(plot_data$group,levels = c("Study 3","Study 5A & 5B","Pooled"))
plot_subincome<-ggplot(plot_data,aes(y=estimate,x=type,group=group)) +
  geom_pointrange(aes(ymin = lower, ymax = upper, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=0.9,linewidth=0.9) +
  geom_pointrange(aes(ymin = lower90, ymax = upper90, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=2,linewidth=2) +
  geom_hline(yintercept=0,color="gray75",linetype="dashed") +
  scale_color_viridis(#alpha=1,
                      begin=1,end=0.0,discrete=T,option="D",guide = guide_legend(override.aes = list(size = 0.75,
                                                                    alpha = 1) )) +
  xlab("") + ylab("Subgroup treatment effect estimate") + ylim(-0.6,1.3) + ggtitle("by Income") +
  coord_flip() + theme_bw() + 
  theme(legend.title = element_blank()
        ,axis.text.y=element_text(size=12,face="bold"))
plot_subincome
#ate_subincome.pdf 
ggsave(file=here::here("Figures","ate_subincome.pdf"),width=8,height=8)

#ordering of n from 100k or more down to 25k to less than 50k
#Caption:Logistic regression estimated peer praise for empathy treatment effect on log likelihood of choosing empathy task, by Income subgroup. The following are N sizes for each of the models, where N represents respondent-trials; n for respondents. For Study 3 100k or more down to 25k to less than 50k (N=,n=): (204,20), (488,49), (765,78), (743,75). For Study 5: (246,82), (358,120), (791,266), (676,228).  Pooled: (450,102), (846,169), (1556,344), (1419,303).  Points plotted at the center of bands are logistic regression coefficients of dependent variable regressed on Peer Praise with respondent-clustered-standard-errors. Bands are 90\% and 95\% confidence intervals.
```

## by Race

Create SI Figure B.30:

```{r subrace}
#keep track of N and n sizes in models:
study3_Nsize<-study3_nsize<-study5_Nsize<-study5_nsize<-pooled_Nsize<-pooled_nsize<-rep(NA,3)

#study 3
long_data3Black<-subset(long_data3,Race=="Black or African American")
#long_data3Hispanic<-subset(long_data3,Race=="Hispanic or Latino")
#long_data3Native<-subset(long_data3,Race=="Native Hawaiian or Pacific Islander"|Race=="Other") #too few obs for sub
long_data3White<-subset(long_data3,Race=="White")
long_data3Other<-subset(long_data3,Race=="Asian"|Race=="Hispanic or Latino"|
                          Race=="Native Hawaiian or Pacific Islander"|
                        Race=="Other") #all bundled smaller groups

ate3Black <- miceadds::glm.cluster( data=long_data3Black, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate3Black) 
  #n
temp<-subset(long_data3Black,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[1]<-dim(temp)[1]
  study3_nsize[1]<-length(unique(temp$ID))

ate3White <- miceadds::glm.cluster( data=long_data3White, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate3White) 
  #n
temp<-subset(long_data3White,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[2]<-dim(temp)[1]
  study3_nsize[2]<-length(unique(temp$ID))

  
ate3Other <- miceadds::glm.cluster(data=long_data3Other, formula=describeORfeel ~ PraiseEmpathy,
                                cluster="ID", family=binomial(link="logit"))
summary(ate3Other) 
  #n
temp<-subset(long_data3Other,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[3]<-dim(temp)[1]
  study3_nsize[3]<-length(unique(temp$ID))
  
#study 5/6
long_data5Black<-subset(long_datapool,Race=="Black or African American")
long_data5White<-subset(long_datapool,Race=="White")
long_data5Other<-subset(long_datapool,Race=="Asian"|Race=="Hispanic or Latino"|
                          Race=="Native Hawaiian or Pacific Islander"|Race=="Other") #all bundled smaller groups
#models
ate5Black <- miceadds::glm.cluster( data=long_data5Black, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate5Black) 
  #n
temp<-subset(long_data5Black,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[1]<-dim(temp)[1]
  study5_nsize[1]<-length(unique(temp$ID))
  
ate5White <- miceadds::glm.cluster( data=long_data5White, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate5White) 
  #n
temp<-subset(long_data5White,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[2]<-dim(temp)[1]
  study5_nsize[2]<-length(unique(temp$ID))
  
ate5Other <- miceadds::glm.cluster(data=long_data5Other, formula=describeORfeel ~ PraiseEmpathy,
                                cluster="ID", family=binomial(link="logit"))
summary(ate5Other) 
  #n
temp<-subset(long_data5Other,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[3]<-dim(temp)[1]
  study5_nsize[3]<-length(unique(temp$ID))
  
#Pooled
long_datatotBlack<-subset(long_datatotpool,Race=="Black or African American")
long_datatotWhite<-subset(long_datatotpool,Race=="White")
long_datatotOther<-subset(long_datatotpool,Race=="Asian"|Race=="Hispanic or Latino"|
                          Race=="Native Hawaiian or Pacific Islander"|Race=="Other")
#models
atetotBlack <- miceadds::glm.cluster( data=long_datatotBlack, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(atetotBlack) 
  #n
temp<-subset(long_datatotBlack,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[1]<-dim(temp)[1]
  pooled_nsize[1]<-length(unique(temp$ID))
  
atetotWhite <- miceadds::glm.cluster( data=long_datatotWhite, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(atetotWhite) 
  #n
temp<-subset(long_datatotWhite,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[2]<-dim(temp)[1]
  pooled_nsize[2]<-length(unique(temp$ID))
  
atetotOther <- miceadds::glm.cluster(data=long_datatotOther, formula=describeORfeel ~ PraiseEmpathy,
                                cluster="ID", family=binomial(link="logit"))
summary(atetotOther) 
  #n
temp<-subset(long_datatotOther,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[3]<-dim(temp)[1]
  pooled_nsize[3]<-length(unique(temp$ID))
```

```{r subrace plot}
#plot data: 3, 5, pooled 
plot_data<-data.frame(group=rep(c("Study 3","Study 5A & 5B","Pooled"),each=3)
           ,type=rep(c("Black","White","Other"),times=3)
           ,estimate=c(coef(ate3Black)[2],coef(ate3White)[2],coef(ate3Other)[2]
                       ,coef(ate5Black)[2],coef(ate5White)[2],coef(ate5Other)[2]
                       ,coef(atetotBlack)[2],coef(atetotWhite)[2],coef(atetotOther)[2])
           ,se=c(summary(ate3Black)[2,2],summary(ate3White)[2,2],summary(ate3Other)[2,2]
                 ,summary(ate5Black)[2,2],summary(ate5White)[2,2],summary(ate5Other)[2,2]
                 ,summary(atetotBlack)[2,2],summary(atetotWhite)[2,2],summary(atetotOther)[2,2]))
plot_data$lower=plot_data$estimate-qnorm(0.975)*plot_data$se
plot_data$upper=plot_data$estimate+qnorm(0.975)*plot_data$se
plot_data$lower90=plot_data$estimate-qnorm(0.95)*plot_data$se
plot_data$upper90=plot_data$estimate+qnorm(0.95)*plot_data$se
#plot
plot_data$type<-factor(plot_data$type,levels = c("Black","White","Other"))
plot_data$group<-factor(plot_data$group,levels = c("Study 3","Study 5A & 5B","Pooled"))
plot_subrace<-ggplot(plot_data,aes(y=estimate,x=type,group=group)) +
  geom_pointrange(aes(ymin = lower, ymax = upper, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=0.9,linewidth=0.9) +
  geom_pointrange(aes(ymin = lower90, ymax = upper90, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=2,linewidth=2) +
  geom_hline(yintercept=0,color="gray75",linetype="dashed") +
  scale_color_viridis(#alpha=1,
                      begin=1,end=0.0,discrete=T,option="D",guide = guide_legend(override.aes = list(size = 0.75,
                                                                    alpha = 1) )) +
  xlab("") + ylab("Subgroup treatment effect estimate") + ylim(-0.6,1.3) + ggtitle("by Race") +
  coord_flip() + theme_bw() + 
  theme(legend.title = element_blank()
        ,axis.text.y=element_text(size=12,face="bold"))
plot_subrace
#ate_subrace.pdf 
ggsave(file=here::here("Figures","ate_subrace.pdf"),width=7,height=8)

#ordering of n from Black, White, Other
#Caption:Logistic regression estimated peer praise for empathy treatment effect on log likelihood of choosing empathy task, by Race subgroup. The following are N sizes for each of the models, where N represents respondent-trials; n for respondents. For Study 3 Black, White and Other subgroups (N=,n=): (492,48), (1765,180), (229,22). For Study 5: (447,149), (1656,557), (209,71).  Pooled: (939,197), (3421,737), (438,93).  Points plotted at the center of bands are logistic regression coefficients of dependent variable regressed on Peer Praise with respondent-clustered-standard-errors. Bands are 90\% and 95\% confidence intervals.
```


## by Education

Create SI Figure B.31:

* Educ levels have too few observations for some categories so we aggregate for some:
  - "Some high school, but did not graduate" and "High school or equivalent (GED)" combined to "HS"
  - "Some college, but did not complete a degree" and "Bachelor's degree (BA/BS)" and "Associate degree" combined to "College"
  - "Master's degree (MA/MS/MBA)" and "Medical (MD), law (JD) or other doctoral degree (PhD)" combined to "Postgrad"
* note 5B had an extra category "no schooling completed" but since this was a single respondent we drop this category.

```{r subeduc}
study3_Nsize<-study5_Nsize<-pooled_Nsize<-rep(NA,3) #respondent-trial obs
study3_nsize<-study5_nsize<-pooled_nsize<-rep(NA,3) #respondent obs
#subset data, run model, store
disagg_educ_levels<- c("Some high school, but did not graduate","High school or equivalent (GED)"
                ,"Some college, but did not complete a degree","Associate degree"
                ,"Bachelor's degree (BA/BS)","Master's degree (MA/MS/MBA)"
                ,"Medical (MD), law (JD) or other doctoral degree (PhD)")
educ_levels<-c("HS","College","Postgrad")
long_data3T<-ate3T<-long_datapoolT<-ate5T<-long_data5T<-atetotT<-vector("list",length(educ_levels))
estimate<-se<-matrix(NA,nrow=length(educ_levels),ncol=3) #rows are approval levels, cols are data source
for(i in 1:length(educ_levels)){
  if(educ_levels[i]=="HS"){
  long_data3T[[i]]<-subset(long_data3,Education=="Some high school, but did not graduate"|
                             Education=="High school or equivalent (GED)")
  ate3T[[i]]<-miceadds::glm.cluster( data=long_data3T[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,1]<-coef(ate3T[[i]])[2]
  se[i,1]<-summary(ate3T[[i]])[2,2]
  temp<-subset(long_data3T[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[i]<-dim(temp)[1]
  study3_nsize[i]<-length(unique(temp$ID))
  
  long_data5T[[i]]<-subset(long_datapool,Education=="Some high school, but did not graduate"|
                             Education=="High school or equivalent (GED)")
  ate5T[[i]]<-miceadds::glm.cluster( data=long_data5T[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,2]<-coef(ate5T[[i]])[2]
  se[i,2]<-summary(ate5T[[i]])[2,2]
  temp<-subset(long_data5T[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[i]<-dim(temp)[1]
  study5_nsize[i]<-length(unique(temp$ID))
  
  long_datatotT[[i]]<-subset(long_datatotpool,Education=="Some high school, but did not graduate"|
                             Education=="High school or equivalent (GED)")
  atetotT[[i]]<-miceadds::glm.cluster( data=long_datatotT[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,3]<-coef(atetotT[[i]])[2]
  se[i,3]<-summary(atetotT[[i]])[2,2]
  temp<-subset(long_datatotT[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[i]<-dim(temp)[1]
  pooled_nsize[i]<-length(unique(temp$ID))
  }
  if(educ_levels[i]=="College"){
  long_data3T[[i]]<-subset(long_data3,Education=="Some college, but did not complete a degree"|
                             Education=="Associate degree"|Education=="Bachelor's degree (BA/BS)")
  ate3T[[i]]<-miceadds::glm.cluster( data=long_data3T[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,1]<-coef(ate3T[[i]])[2]
  se[i,1]<-summary(ate3T[[i]])[2,2]
  temp<-subset(long_data3T[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[i]<-dim(temp)[1]
  study3_nsize[i]<-length(unique(temp$ID))
  
  long_data5T[[i]]<-subset(long_datapool,Education=="Some college, but did not complete a degree"|
                             Education=="Associate degree"|Education=="Bachelor's degree (BA/BS)")
  ate5T[[i]]<-miceadds::glm.cluster( data=long_data5T[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,2]<-coef(ate5T[[i]])[2]
  se[i,2]<-summary(ate5T[[i]])[2,2]
  temp<-subset(long_data5T[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[i]<-dim(temp)[1]
  study5_nsize[i]<-length(unique(temp$ID))
  
  long_datatotT[[i]]<-subset(long_datatotpool,Education=="Some college, but did not complete a degree"|
                             Education=="Associate degree"|Education=="Bachelor's degree (BA/BS)")
  atetotT[[i]]<-miceadds::glm.cluster( data=long_datatotT[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,3]<-coef(atetotT[[i]])[2]
  se[i,3]<-summary(atetotT[[i]])[2,2]
  temp<-subset(long_datatotT[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[i]<-dim(temp)[1]
  pooled_nsize[i]<-length(unique(temp$ID))
  
  }else{#"Master's degree (MA/MS/MBA)" and "Medical (MD), law (JD) or other doctoral degree (PhD)"
  long_data3T[[i]]<-subset(long_data3,Education=="Master's degree (MA/MS/MBA)"|
                             Education=="Medical (MD), law (JD) or other doctoral degree (PhD)")
  ate3T[[i]]<-miceadds::glm.cluster( data=long_data3T[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,1]<-coef(ate3T[[i]])[2]
  se[i,1]<-summary(ate3T[[i]])[2,2]
  temp<-subset(long_data3T[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[i]<-dim(temp)[1]
  study3_nsize[i]<-length(unique(temp$ID))
  
  long_data5T[[i]]<-subset(long_datapool,Education=="Master's degree (MA/MS/MBA)"|
                             Education=="Medical (MD), law (JD) or other doctoral degree (PhD)")
  ate5T[[i]]<-miceadds::glm.cluster( data=long_data5T[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,2]<-coef(ate5T[[i]])[2]
  se[i,2]<-summary(ate5T[[i]])[2,2]
  temp<-subset(long_data5T[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[i]<-dim(temp)[1]
  study5_nsize[i]<-length(unique(temp$ID))
  
  long_datatotT[[i]]<-subset(long_datatotpool,Education=="Master's degree (MA/MS/MBA)"|
                             Education=="Medical (MD), law (JD) or other doctoral degree (PhD)")
  atetotT[[i]]<-miceadds::glm.cluster( data=long_datatotT[[i]]
               ,formula=describeORfeel ~ PraiseEmpathy,cluster="ID", family=binomial(link="logit"))
  estimate[i,3]<-coef(atetotT[[i]])[2]
  se[i,3]<-summary(atetotT[[i]])[2,2]    
  temp<-subset(long_datatotT[[i]],select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[i]<-dim(temp)[1]
  pooled_nsize[i]<-length(unique(temp$ID))
  }
}


```

```{r subeduc plot}
#plot data: 
plot_data<-data.frame(group=rep(c("Study 3","Study 5A & 5B", "Pooled"),each=length(educ_levels))
           ,type=rep(educ_levels,times=3)
           ,estimate=c(estimate) #column unroll
           ,se=c(se))
plot_data$lower=plot_data$estimate-qnorm(0.975)*plot_data$se
plot_data$upper=plot_data$estimate+qnorm(0.975)*plot_data$se
plot_data$lower90=plot_data$estimate-qnorm(0.95)*plot_data$se
plot_data$upper90=plot_data$estimate+qnorm(0.95)*plot_data$se
#plot
plot_data$type<-factor(plot_data$type,levels = educ_levels)
plot_data$group<-factor(plot_data$group,levels = c("Study 3","Study 5A & 5B","Pooled"))
plot_subeduc<-ggplot(plot_data,aes(y=estimate,x=type,group=group)) +
  geom_pointrange(aes(ymin = lower, ymax = upper, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=0.9, linewidth=0.9) +
  geom_pointrange(aes(ymin = lower90, ymax = upper90, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=2, linewidth=2) +
  geom_hline(yintercept=0,color="gray75",linetype="dashed") +
  scale_color_viridis(#alpha=1,
                      begin=1,end=0,discrete=T,option="D",guide = guide_legend(override.aes = list(size = 0.75,
                                                                    alpha = 1) )) +
  xlab("") + ylab("Subgroup treatment effect estimate") + ylim(-1.1,1.1) + ggtitle("by Education") +
  coord_flip() + theme_bw() + 
  theme(legend.title = element_blank()
        ,axis.text.y=element_text(size=12,face="bold"))
plot_subeduc
#ate_subeduc.pdf 6x6

ggsave(file=here::here("Figures","ate_subeduc.pdf"),width=7,height=8)

#ordering of n from HS, College, Postgrad
#Caption:Logistic regression estimated peer praise for empathy treatment effect on log likelihood of choosing empathy task, by Education subgroup. The following are N sizes for each of the models, where N represents respondent-trials; n for respondents. For Study 3 HS, College and Postgrad subgroups (N=,n=): (565,56), (1692,170), (565,56). For Study 5: (525,176), (1658,558), (525,176).  Pooled: (1090,232), (3350,728), (1090,232). Points plotted at the center of bands are logistic regression coefficients of dependent variable regressed on Peer Praise with respondent-clustered-standard-errors. Bands are 90\% and 95\% confidence intervals.
```

## by Sex

Create SI Figure B.32:

```{r subsex}
#keep track of N and n sizes in models:
study3_Nsize<-study3_nsize<-study5_Nsize<-study5_nsize<-pooled_Nsize<-pooled_nsize<-rep(NA,2)

#study 3
long_data3F<-subset(long_data3,Sex=="Female")
long_data3M<-subset(long_data3,Sex=="Male")
ate3F <- miceadds::glm.cluster( data=long_data3F, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate3F) 
  temp<-subset(long_data3F,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[1]<-dim(temp)[1]
  study3_nsize[1]<-length(unique(temp$ID))
ate3M <- miceadds::glm.cluster( data=long_data3M, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate3M) 
  temp<-subset(long_data3M,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[2]<-dim(temp)[1]
  study3_nsize[2]<-length(unique(temp$ID))
#study 5/6
long_data5F<-subset(long_datapool,Sex=="Female")
long_data5M<-subset(long_datapool,Sex=="Male")
#models
ate5F <- miceadds::glm.cluster( data=long_data5F, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate5F) 
  temp<-subset(long_data5F,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[1]<-dim(temp)[1]
  study5_nsize[1]<-length(unique(temp$ID))
ate5M <- miceadds::glm.cluster( data=long_data5M, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate5M) 
  temp<-subset(long_data5M,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[2]<-dim(temp)[1]
  study5_nsize[2]<-length(unique(temp$ID))
#3,5,6
long_datatotF<-subset(long_datatotpool,Sex=="Female")
long_datatotM<-subset(long_datatotpool,Sex=="Male")
#models
atetotF <- miceadds::glm.cluster( data=long_datatotF, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(atetotF) 
  temp<-subset(long_datatotF,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[1]<-dim(temp)[1]
  pooled_nsize[1]<-length(unique(temp$ID))
atetotM <- miceadds::glm.cluster( data=long_datatotM, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(atetotM) 
  temp<-subset(long_datatotM,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[2]<-dim(temp)[1]
  pooled_nsize[2]<-length(unique(temp$ID))
```

```{r subsex plot}
#plot data: 
plot_data<-data.frame(group=rep(c("Study 3","Study 5A & 5B","Pooled"),each=2)
           ,type=rep(c("Female","Male"),times=3)
           ,estimate=c(coef(ate3F)[2],coef(ate3M)[2]
                       ,coef(ate5F)[2],coef(ate5M)[2]
                       ,coef(atetotF)[2],coef(atetotM)[2])
           ,se=c(summary(ate3F)[2,2],summary(ate3M)[2,2]
                 ,summary(ate5F)[2,2],summary(ate5M)[2,2]
                 ,summary(atetotF)[2,2],summary(atetotM)[2,2]))
plot_data$lower=plot_data$estimate-qnorm(0.975)*plot_data$se
plot_data$upper=plot_data$estimate+qnorm(0.975)*plot_data$se
plot_data$lower90=plot_data$estimate-qnorm(0.95)*plot_data$se
plot_data$upper90=plot_data$estimate+qnorm(0.95)*plot_data$se
#plot
plot_data$type<-factor(plot_data$type,levels = c("Female","Male"))
plot_data$group<-factor(plot_data$group,levels = c("Study 3","Study 5A & 5B","Pooled"))
plot_subsex<-ggplot(plot_data,aes(y=estimate,x=type,group=group)) +
  geom_pointrange(aes(ymin = lower, ymax = upper, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=0.9, linewidth=0.9) +
  geom_pointrange(aes(ymin = lower90, ymax = upper90, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=2,linewidth=2) +
  geom_hline(yintercept=0,color="gray75",linetype="dashed") +
  scale_color_viridis(#alpha=1,
                      begin=1,end=0.0,discrete=T,option="D",guide = guide_legend(override.aes = list(size = 0.75,
                                                                    alpha = 1) )) +
  xlab("") + ylab("Subgroup treatment effect estimate") + ylim(-0.2,0.8) + ggtitle("by Sex") +
  coord_flip() + theme_bw() + 
  theme(legend.title = element_blank()
        ,axis.text.y=element_text(size=12,face="bold"))
plot_subsex
#ate_subsex.pdf 

ggsave(file=here::here("Figures","ate_subsex.pdf"),width=7,height=8)

#ordering of n from F, M
#Caption:Logistic regression estimated peer praise for empathy treatment effect on log likelihood of choosing empathy task, by Sex subgroup. The following are N sizes for each of the models, where N represents respondent-trials; n for respondents. For Study 3 Female, Male subgroups (N=,n=): (997,99), (1503,153). For Study 5: (887,298), (1464,492).  Pooled: (1884,397), (2967,645). Points plotted at the center of bands are logistic regression coefficients of dependent variable regressed on Peer Praise with respondent-clustered-standard-errors. Bands are 90\% and 95\% confidence intervals.
```

## by baseline Empathy

Create SI Figure B.33:

We're going to split by baseline empathy battery terciles.

```{r subbaseempathy}
#keep track of N and n sizes in models:
study3_Nsize<-study3_nsize<-study5_Nsize<-study5_nsize<-pooled_Nsize<-pooled_nsize<-rep(NA,3)

#study 3
long_data3lowemp<-subset(long_data3,BaseEmpathy_tercile=="Low")
long_data3medemp<-subset(long_data3,BaseEmpathy_tercile=="Medium")
long_data3highemp<-subset(long_data3,BaseEmpathy_tercile=="High")
#models
ate3lowemp <- miceadds::glm.cluster( data=long_data3lowemp, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate3lowemp) 
  temp<-subset(long_data3lowemp,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[1]<-dim(temp)[1]
  study3_nsize[1]<-length(unique(temp$ID))
ate3medemp <- miceadds::glm.cluster( data=long_data3medemp, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate3medemp) 
  temp<-subset(long_data3medemp,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[2]<-dim(temp)[1]
  study3_nsize[2]<-length(unique(temp$ID))
ate3highemp <- miceadds::glm.cluster( data=long_data3highemp, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate3highemp) 
  temp<-subset(long_data3highemp,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study3_Nsize[3]<-dim(temp)[1]
  study3_nsize[3]<-length(unique(temp$ID))
  
#study 5/6
long_data5lowemp<-subset(long_datapool,BaseEmpathy_tercile=="Low")
long_data5medemp<-subset(long_datapool,BaseEmpathy_tercile=="Medium")
long_data5highemp<-subset(long_datapool,BaseEmpathy_tercile=="High")
#models
ate5lowemp <- miceadds::glm.cluster( data=long_data5lowemp, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate5lowemp) 
  temp<-subset(long_data5lowemp,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[1]<-dim(temp)[1]
  study5_nsize[1]<-length(unique(temp$ID))
ate5medemp <- miceadds::glm.cluster( data=long_data5medemp, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate5medemp) 
  temp<-subset(long_data5medemp,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[2]<-dim(temp)[1]
  study5_nsize[2]<-length(unique(temp$ID))
ate5highemp <- miceadds::glm.cluster( data=long_data5highemp, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(ate5highemp) 
  temp<-subset(long_data5highemp,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5_Nsize[3]<-dim(temp)[1]
  study5_nsize[3]<-length(unique(temp$ID))
  
#all
long_datatotlowemp<-subset(long_datatotpool,BaseEmpathy_tercile=="Low")
long_datatotmedemp<-subset(long_datatotpool,BaseEmpathy_tercile=="Medium")
long_datatothighemp<-subset(long_datatotpool,BaseEmpathy_tercile=="High")
#models
atetotlowemp <- miceadds::glm.cluster( data=long_datatotlowemp, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(atetotlowemp) 
  temp<-subset(long_datatotlowemp,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[1]<-dim(temp)[1]
  pooled_nsize[1]<-length(unique(temp$ID))
  
atetotmedemp <- miceadds::glm.cluster( data=long_datatotmedemp, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(atetotmedemp) 
  temp<-subset(long_datatotmedemp,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[2]<-dim(temp)[1]
  pooled_nsize[2]<-length(unique(temp$ID))
atetothighemp <- miceadds::glm.cluster( data=long_datatothighemp, formula=describeORfeel ~ PraiseEmpathy,
               cluster="ID", family=binomial(link="logit"))
summary(atetothighemp) 
  temp<-subset(long_datatothighemp,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[3]<-dim(temp)[1]
  pooled_nsize[3]<-length(unique(temp$ID))
```

```{r subbaseempathy plot}
#plot data: 5, 6, pooled 
plot_data<-data.frame(group=rep(c("Study 3","Study 5A & 5B","Pooled"),each=3)
           ,type=rep(c("Low","Medium","High"),times=3)
           ,estimate=c(coef(ate3lowemp)[2],coef(ate3medemp)[2],coef(ate3highemp)[2]
                       ,coef(ate5lowemp)[2],coef(ate5medemp)[2],coef(ate5highemp)[2]
                       ,coef(atetotlowemp)[2],coef(atetotmedemp)[2],coef(atetothighemp)[2])
           ,se=c(summary(ate3lowemp)[2,2],summary(ate3medemp)[2,2],summary(ate3highemp)[2,2]
                 ,summary(ate5lowemp)[2,2],summary(ate5medemp)[2,2],summary(ate5highemp)[2,2]
                 ,summary(atetotlowemp)[2,2],summary(atetotmedemp)[2,2],summary(atetothighemp)[2,2]))
plot_data$lower=plot_data$estimate-qnorm(0.975)*plot_data$se
plot_data$upper=plot_data$estimate+qnorm(0.975)*plot_data$se
plot_data$lower90=plot_data$estimate-qnorm(0.95)*plot_data$se
plot_data$upper90=plot_data$estimate+qnorm(0.95)*plot_data$se
#plot
plot_data$type<-factor(plot_data$type,levels = c("Low","Medium","High"))
plot_data$group<-factor(plot_data$group,levels = c("Study 3","Study 5A & 5B","Pooled"))
plot_subbaseempathy<-ggplot(plot_data,aes(y=estimate,x=type,group=group)) +
  geom_pointrange(aes(ymin = lower, ymax = upper, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=0.9,linewidth=0.9) +
  geom_pointrange(aes(ymin = lower90, ymax = upper90, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=2,linewidth=2) +
  geom_hline(yintercept=0,color="gray75",linetype="dashed") +
  scale_color_viridis(#alpha=1,
                      begin=1,end=0,discrete=T,option="D",guide = guide_legend(override.aes = list(size = 0.75,
                                                                    alpha = 1) )) +
  xlab("") + ylab("Subgroup treatment effect estimate") + ylim(-0.3,0.8) + ggtitle("by baseline empathy battery") +
  coord_flip() + theme_bw() + 
  theme(legend.title = element_blank()
        ,axis.text.y=element_text(size=12,face="bold"))
plot_subbaseempathy
#ate_subbaseempathy.pdf

ggsave(file=here::here("Figures","ate_subbaseempathy.pdf"),width=7,height=8)

#ordering of n from L, M, H
#Caption:Logistic regression estimated peer praise for empathy treatment effect on log likelihood of choosing empathy task, by empathy battery tercile subgroup. The following are N sizes for each of the models, where N represents respondent-trials; n for respondents. For Study 3 Low, Medium, High subgroups (N=,n=): (861,90), (942,93), (634,61). For Study 5: (884,295), (702,234), (699,233).  Pooled: (1745,385), (1833,390), (1144,231). Points plotted at the center of bands are logistic regression coefficients of dependent variable regressed on Peer Praise with respondent-clustered-standard-errors. Bands are 90\% and 95\% confidence intervals.
```

## by Attentiveness

Create SI Figure B.34:

* key variables `attentionG` and `attentionMC`: which combine to `attention`; we're going to subset into attention==2 for attentive respondents, attention==1 for half attentive (scored only 1 for either the grid *or* multiple choice attention check correctly, but  not both) and attention==0 for unattentive (didn't score for either attention check).

```{r subattentiveness}
#keep track of N and n sizes in models:
study5a_Nsize<-study5a_nsize<-study5b_Nsize<-study5b_nsize<-pooled_Nsize<-pooled_nsize<-rep(NA,3)

#study 5a
attentive_long5<-subset(long_data5_new,attention==2)
halfattentive_long5<-subset(long_data5_new,attention==1)
unattentive_long5<-subset(long_data5_new,attention==0)
ate_attentive5 <- miceadds::glm.cluster( data=attentive_long5
                                         , formula=describeORfeel ~ PraiseEmpathy 
               ,cluster="ID", family=binomial(link="logit"))
summary(ate_attentive5)
  temp<-subset(attentive_long5,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5a_Nsize[1]<-dim(temp)[1]
  study5a_nsize[1]<-length(unique(temp$ID))
  
ate_halfattentive5 <- miceadds::glm.cluster( data=halfattentive_long5
                                         , formula=describeORfeel ~ PraiseEmpathy 
               ,cluster="ID", family=binomial(link="logit"))
summary(ate_halfattentive5)
  temp<-subset(halfattentive_long5,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5a_Nsize[2]<-dim(temp)[1]
  study5a_nsize[2]<-length(unique(temp$ID))
  
ate_unattentive5 <- miceadds::glm.cluster( data=unattentive_long5
                                         , formula=describeORfeel ~ PraiseEmpathy 
               ,cluster="ID", family=binomial(link="logit"))
summary(ate_unattentive5)
  temp<-subset(unattentive_long5,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5a_Nsize[3]<-dim(temp)[1]
  study5a_nsize[3]<-length(unique(temp$ID))
  
#study 5b
attentive_long6<-subset(long_data6_new,attention==2)
halfattentive_long6<-subset(long_data6_new,attention==1)
unattentive_long6<-subset(long_data6_new,attention==0)
ate_attentive6 <- miceadds::glm.cluster( data=attentive_long6
                                         , formula=describeORfeel ~ PraiseEmpathy 
               ,cluster="ID", family=binomial(link="logit"))
summary(ate_attentive6)
  temp<-subset(attentive_long6,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5b_Nsize[1]<-dim(temp)[1]
  study5b_nsize[1]<-length(unique(temp$ID))
  
ate_halfattentive6 <- miceadds::glm.cluster( data=halfattentive_long6
                                         , formula=describeORfeel ~ PraiseEmpathy 
               ,cluster="ID", family=binomial(link="logit"))
summary(ate_halfattentive6)
  temp<-subset(halfattentive_long6,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5b_Nsize[2]<-dim(temp)[1]
  study5b_nsize[2]<-length(unique(temp$ID))
ate_unattentive6 <- miceadds::glm.cluster( data=unattentive_long6
                                         , formula=describeORfeel ~ PraiseEmpathy 
               ,cluster="ID", family=binomial(link="logit"))
summary(ate_unattentive6)
  temp<-subset(unattentive_long6,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  study5b_Nsize[3]<-dim(temp)[1]
  study5b_nsize[3]<-length(unique(temp$ID))
#pooled 5a,5b
attentive_longpool<-subset(long_datapool,attention==2)
halfattentive_longpool<-subset(long_datapool,attention==1)
unattentive_longpool<-subset(long_datapool,attention==0)
ate_attentivepool <- miceadds::glm.cluster( data=attentive_longpool
                                         , formula=describeORfeel ~ PraiseEmpathy 
               ,cluster="ID", family=binomial(link="logit"))
summary(ate_attentivepool)
  temp<-subset(attentive_longpool,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[1]<-dim(temp)[1]
  pooled_nsize[1]<-length(unique(temp$ID))
ate_halfattentivepool <- miceadds::glm.cluster( data=halfattentive_longpool
                                         , formula=describeORfeel ~ PraiseEmpathy 
               ,cluster="ID", family=binomial(link="logit"))
summary(ate_halfattentivepool)
  temp<-subset(halfattentive_longpool,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[2]<-dim(temp)[1]
  pooled_nsize[2]<-length(unique(temp$ID))
ate_unattentivepool <- miceadds::glm.cluster( data=unattentive_longpool
                                         , formula=describeORfeel ~ PraiseEmpathy 
               ,cluster="ID", family=binomial(link="logit"))
summary(ate_unattentivepool)
  temp<-subset(unattentive_longpool,select=c("describeORfeel","PraiseEmpathy","ID"))
  temp<-temp[complete.cases(temp),]
  pooled_Nsize[3]<-dim(temp)[1]
  pooled_nsize[3]<-length(unique(temp$ID))
```

```{r subattentiveness plot}
#plot data: 5, 6, pooled 
plot_data<-data.frame(group=rep(c("Study 5A","Study 5B","Pooled"),each=3)
           ,type=rep(c("Attentive","Somewhat Attentive","Inattentive"),times=3)
           ,estimate=c(coef(ate_attentive5)[2],coef(ate_halfattentive5)[2],coef(ate_unattentive5)[2]
                       ,coef(ate_attentive6)[2],coef(ate_halfattentive6)[2],coef(ate_unattentive6)[2]
                       ,coef(ate_attentivepool)[2],coef(ate_halfattentivepool)[2],coef(ate_unattentivepool)[2])
           ,se=c(summary(ate_attentive5)[2,2],summary(ate_halfattentive5)[2,2],summary(ate_unattentive5)[2,2]
                 ,summary(ate_attentive6)[2,2],summary(ate_halfattentive6)[2,2],summary(ate_unattentive6)[2,2]
                 ,summary(ate_attentivepool)[2,2],summary(ate_halfattentivepool)[2,2],summary(ate_unattentivepool)[2,2]))
plot_data$lower=plot_data$estimate-qnorm(0.975)*plot_data$se
plot_data$upper=plot_data$estimate+qnorm(0.975)*plot_data$se
plot_data$lower90=plot_data$estimate-qnorm(0.95)*plot_data$se
plot_data$upper90=plot_data$estimate+qnorm(0.95)*plot_data$se
#plot
plot_data$type<-factor(plot_data$type,levels = c("Inattentive","Somewhat Attentive","Attentive"))
plot_data$group<-factor(plot_data$group,levels = c("Study 5A","Study 5B","Pooled"))
plot_subattentive<-ggplot(plot_data,aes(y=estimate,x=type,group=group)) +
  geom_pointrange(aes(ymin = lower, ymax = upper, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=0.9, linewidth=0.9) +
  geom_pointrange(aes(ymin = lower90, ymax = upper90, color = group),
                    position = position_dodge(width = 0.2), fatten = 1.5, size=2,linewidth=2) +
  geom_hline(yintercept=0,color="gray75",linetype="dashed") +
  scale_color_viridis(#alpha=1,
                      begin=1,end=0,discrete=T,option="D",guide = guide_legend(override.aes = list(size = 0.75,
                                                                    alpha = 1) )) +
  xlab("") + ylab("Subgroup treatment effect estimate") + ylim(-1.5,1.25) + ggtitle("by Attentiveness") +
  coord_flip() + theme_bw() + 
  theme(legend.title = element_blank()
        ,axis.text.y=element_text(size=12,face="bold"))
plot_subattentive
#ate_subattentive.pdf 6x7

ggsave(file=here::here("Figures","ate_subattentive.pdf"),width=7,height=8)

#ordering of n from Attentive, Somewhat Attentive, Inattentive
#Caption:Logistic regression estimated peer praise for empathy treatment effect on log likelihood of choosing empathy task, by Attentiveness subgroup. The following are N sizes for each of the models, where N represents respondent-trials; n for respondents. For Study 5a Attentive, Somewhat Attentive, Inattentive subgroups (N=,n=): (563,189), (245,82), (50,17). For Study 5b: (941,317), (459,154), (102,34).  Pooled: (1504,506), (704,236), (152,51). Points plotted at the center of bands are logistic regression coefficients of dependent variable regressed on Peer Praise with respondent-clustered-standard-errors. Bands are 90\% and 95\% confidence intervals.
```

## over Time


Create SI Figure B.35:

* using `long_data5`

**Fading effects of praise:**
In all models, `describeORfeel` is regressed over `PraiseEmpathy`, estimating the effect of praise FEEL on selecting to perform task FEEL. Each model estimates this effect for the cumulative trials, starting with 1, then 1-2, 2-3, and so on.

**AMCE and ADE changes over increasing trials**

**Fading effects of praise:**
[In all models, `describeORfeel` is regressed over `PraiseEmpathy`, estimating the effect of praise FEEL on selecting to perform task FEEL. Each model estimates this effect for the cumulative trials, starting with 1, then 1-2, 2-3, and so on.]{color="navy"}

**AMCE and ADE changes over increasing trials**

```{r, eval=FALSE}
plot_data <-data.frame(Trial=factor(paste("Trial",1:20, sep=" "),levels = paste("Trial",1:20, sep=" "))
                       ,Estimate=NA,Low=NA,High=NA
                       ,ACME=NA,ACME_low=NA,ACME_high=NA
                       ,TE=NA,TE_low=NA,TE_high=NA,N=NA)
for(i in 1:length(unique(long_data5$trial_no))){
  print(i)
  tmp_trial <- unique(long_data5$trial_no)[i]
  tmp_data <- subset(long_data5,trial_no <= tmp_trial & !is.na(happy))
  tmp_data <-subset(tmp_data,select=c("describeORfeel","PraiseEmpathy","happy","ID")) #added to fix bug of unmatched obs for mediation and outcome equations
  tmp_data <-tmp_data[complete.cases(tmp_data),] #added to fix bug of unmatched obs for mediation and outcome equations
  plot_data$N[i]<-nrow(tmp_data)
  happy_med <- lm(happy ~ PraiseEmpathy, data= tmp_data)
  happy_out <- lm(describeORfeel~PraiseEmpathy + happy, data = tmp_data)
  mediation_happy <-  mediate(happy_med, happy_out, treat = "PraiseEmpathy", mediator = "happy"
                              , boot=F, conf.level=.95, sims=1000,cluster=tmp_data$ID)
  summ<-summary(mediation_happy)
  plot_data$ACME[i]<-summ$d.avg
  plot_data$ACME_low[i]<-summ$d.avg.ci[1]
  plot_data$ACME_high[i]<-summ$d.avg.ci[2]
  plot_data$TE[i]<-summ$tau.coef
  plot_data$TE_low[i]<-summ$tau.ci[1]
  plot_data$TE_high[i]<-summ$tau.ci[2]
}
#long ver
plot_data_long<-data.frame(Trial=rep(plot_data$Trial,2)
                           ,Estimand=as.factor(c(rep("ACME",20),rep("TE",20)))
                           #,EstimandColor=c(rep('firebrick3',20),rep('darkblue',20))
                           ,Estimate=c(plot_data$ACME,plot_data$TE)
                           ,Low=c(plot_data$ACME_low,plot_data$TE_low)
                           ,High=c(plot_data$ACME_high,plot_data$TE_high))
saveRDS(plot_data,file=here::here("5a_cumplot_data.rds"))
saveRDS(plot_data_long,file=here::here("5a_cumplot_data_long.rds"))
```

```{r, eval=TRUE, fig.width=10, fig.height=8}
plot_data_long<-readRDS(file=here::here("5a_cumplot_data_long.rds"))
estimand.colors <- c(ACME = "firebrick3", TE = "darkblue")

 ggplot(plot_data_long,aes(x=Trial, y=Estimate)) +
   geom_pointrange(aes(ymin = Low, ymax = High, color=Estimand),
                  position = position_dodge(width = 0.4)) +
   geom_hline(yintercept = 0, color = "gray50", linetype = 2, size = 0.2) +
   scale_color_manual(values=estimand.colors) +
   labs(x = "Cumulative trials",
       y = "Estimated Effect Size") +
  theme(text = element_text(size = 10, family = "Times"),
        legend.key=element_blank(),
        panel.grid.major = element_blank(), 
        axis.text.x = element_text(size = 10),
        plot.caption = element_text(size = 10, family = "Times",hjust = -.02),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black"))
 
#cum_acme_te.pdf 
 
ggsave(file=here::here("Figures","cum_acme_te.pdf"),width=10,height=8)
#n sizes in plot_data object
 #Caption: {\bf Mediation analyses estimated average causal marginal effects (ACME) and total effects (TE) for peer praise on empathy (through happiness) over successive main task trials in Pilot 5a.} Models follow the linear regression-based approach in \cite{imai_identification_2010} and use the R package \texttt{mediation}. The following are N sizes for each of the models for each (cumulative) trial: (287, 574, 858, 1141, 1422, 1704, 1986, 2264, 2541, 2820, 3097, 3375, 3653, 3932, 4211, 4488, 4766, 5042, 5319, 5597). Points plotted at the center of bands are estimates of ACME and TE, while bands are 95\% confidence intervals.
```
# Other SI Calculations

We found that the empathy option was 39.7\% less likely to be chosen by respondents than the descriptive one (GLM logit exponentiated coefficient estimate = 0.603, z=-5.638, p=1.722e-08, CI$[0.506,0.719]$) and---in a modified version of the task that included an incentive compatible reservation wage-elicitation stage (``wage task'')---we estimated that choices to engage in empathy required a 10\% premium in wages to motivate our respondents (t = $7.740$, p=$1.277e-13$, CI$[1.077, \text{Inf}]$).

Costs of empathy
```{r costwage}
cost1<-miceadds::glm.cluster( data=long_data1, formula=describeORfeel ~ 1, cluster="ID", family=binomial(link="logit"))
summary(cost1)
#GLM logit exponentiated coefficient estimate
round(exp(coef(cost1)),3)#[Odds ratio to %: (OR-1) * 100] 39.7% lower likelihood of choosing empathy task over objective task
#z-value
round(summary(cost1)[3],3)
#p-value
round(summary(cost1)[4],3)
#CI
exp(confint(cost1))
#"We found that the empathy option was 39.7\% less likely to be chosen by respondents than the descriptive one..."
#Baseline odds of choosing empathy over objective task is `r exp(coef(cost1))`.
#"we estimated that choices to engage in empathy required a 10\% premium in wages to motivate our respondents": t, p, CI
t.test(data1$reservationpay_real, mu = 1, alternative = "greater")
```
 "Here, we found that the peer-praise group was 20\% more likely to choose empathy compared to a control group that did not receive praise "
```{r}
###

#praise-feel vs praise-describe
ate2 <- miceadds::glm.cluster( data=long_data3, formula=describeORfeel ~ PraiseEmpathy_a,
               cluster="ID", family=binomial(link="logit"))
summary(ate2)#log odds output: baseline of choosing empathy is -0.336; differences in log-odds of choosing empathy and objective tasks is 0.106. p=0.16

```
"While ``peer praise for empathy"  slightly increased respondents’ perception that people generally view empathy favorably (from 70.9 to 72.7), the effect was not statistically significant"

```{r praiseempathy-empnorm}
#Praise vs Control
ate1 <- lm(formula=PeopleThinkEmpathyGood ~ PraiseEmpathy,data=data4)
summary(ate1) 
confint(ate1)

ate2 <- lm(formula=PeopleThinkEmpathyGood ~ PraiseEmpathy + describeORfeel + PraiseEmpathy*describeORfeel,data=data4)
summary(ate2) 
ate3 <- lm(formula=SelfThinkEmpathyGood ~ PraiseEmpathy + describeORfeel + PraiseEmpathy*describeORfeel,data=data4)
summary(ate3) 

#Study DLABSS
ate1 <- lm(formula=PeopleThinkEmpathyGood ~ PraiseCoRace + describeORfeel + PraiseCoRace*describeORfeel,data=data7_attentive)
summary(ate1) 
ate2 <- lm(formula=SelfThinkEmpathyGood ~ PraiseCoRace + describeORfeel + PraiseCoRace*describeORfeel,data=data7_attentive)
summary(ate2) 
```

In Pilot Studies 4 and 5, we found relatively strong support for peer praise operating through an emotional pathway (happiness) to encourage greater empathy towards generalized others --- 16\% of the total effect of peer praise is estimated to be mediated through happiness (p=$0.006$, Quasi-Bayesian 95\% CI$[0.06,0.54]$).

```{r}
set.seed(12345)
nsims=10000
happy_med <- lm(happy ~ PraiseEmpathy, data=long_datapool )
happy_out <- glm(describeORfeel~PraiseEmpathy + happy, data = long_datapool, family=binomial(link="logit"))

mediation_happypool <-  mediate(happy_med, happy_out, treat = "PraiseEmpathy", mediator = "happy", boot=FALSE, conf.level=.95, sims=nsims,cluster=long_datapool$ID_pool)
mediation_happypool_90 <-  mediate(happy_med, happy_out, treat = "PraiseEmpathy", mediator = "happy", boot=FALSE, conf.level=.9, sims=nsims,cluster=long_datapool$ID_pool)

saveRDS(mediation_happypool,here::here("mediation_happypool.rds"))
mediation_happypool<-readRDS(here::here("mediation_happypool.rds"))
summary(mediation_happypool) 
#Prop. Mediated (average)  Estim: 0.16275, CI: 0.06434, 0.54; p=0.0056 **
```

We found that the likelihood of the peer praised group choosing to empathize when seeing a racial outgroup member was 0.42, a 0.17 increase from the control group average of 0.25. Footnote: OLS estimate of the regression coefficient of peer praise on choosing to empathize: $0.17$, df=202, t=$2.543$, p=$0.0117$, CI= $[0.037, 0.296]$}.
```{r}
## version used for power calcs: lm test of PraiseEmpathy on FEEL for Whites who pass attention checks and see Outgroup images on first trial
#"OLS estimate of the regression coefficient of peer praise on choosing to empathize:$0.17$, df=202, t=2.543, p=$0.0117$, CI= $[0.037, 0.296]$."
model1<-lm(describeORfeel~PraiseEmpathy,data=data6PE_1) ##***##
summary(model1)
confint(model1)
#0.16667
```

For example, Democrat co-partisan peer praise has a positive effect on empathizing  ($0.184$, t=$2.417$, p=$0.0165$, CI$[0.034, 0.334]$) and choosing to learn about BLM ($0.172$, t$=2.478$, p$=0.014$, CI$[0.035, 0.309]$), while Republican co-partisan peer praise has a negatively signed but not significant effect on empathizing ($-0.102$, t=$-1.377$, p=$0.17$, CI$[-0.249, 0.044]$), and negative effect on willingness to learn about BLM ($-0.13$, t=-$2.102$, p=$0.04$, CI$[-0.25, -0.008]$). 

```{r praiseempathy-coparty}
#"For example, Democrat co-partisan peer praise has a positive effect on empathizing"
ate1<- lm(formula = describeORfeel~PraiseDem,data=data7)
summary(ate1) 
confint(ate1)
#"and choosing to learn about BLM"
ate2<- lm(formula = BLM~PraiseDem,data=data7)
summary(ate2) 
confint(ate2)
#"while Republican co-partisan peer praise has a negatively signed but not significant effect on empathizing"
ate3<- lm(formula = describeORfeel~PraiseRep,data=data7)
summary(ate3) 
confint(ate3)
#"and negative effect on willingness to learn about BLM"
ate4<- lm(formula = BLM~PraiseRep,data=data7)
summary(ate4) 
confint(ate4)

ate5<-lm(formula=describeORfeel~PraiseCoParty,data7)
summary(ate5)
confint(ate5)

ate6<-lm(formula=BLM~PraiseCoParty,data7)
summary(ate6)
confint(ate6)

```

When primed with praise for the feel task, respondents are 4.4\% (p=0.023, estimate=0.044, CI$[0.006, 0.082]$) more likely to select the Feel task (baseline is 0.391).

```{r,eval=TRUE,message=FALSE,warning=FALSE}
#"When primed with praise for the feel task, respondents are \hl{4.4\% (p=0.023, estimate=0.044, CI$[0.006, 0.082]$)} more likely to select the Feel task (baseline is 0.391) "
model_1a <- miceadds::lm.cluster( data=long_data3, formula=describeORfeel ~ PraiseEmpathy, cluster="ID" )
summary(model_1a)
confint(model_1a)
```

When compared to the praise-describe condition, respondents primed with praise for the feel task, respondents are 2.6%... more likely to select the Feel task...
```{r}
model_1b <- miceadds::lm.cluster( data=long_data3, formula=describeORfeel ~ PraiseEmpathy_a,
               cluster="ID" )
summary(model_1b)
confint(model_1b)
```

# Other Main Text Calculations
Costs of empathy
```{r costwage}
#"we estimated that choices to engage in empathy required a 10\% premium in wages to motivate our respondents": t, p, CI
t.test(data1$reservationpay_real, mu = 1, alternative = "greater")
```


For H1, we take effect and SD information from Pilot Study 6, which also examined the effect of peer praise on our behavioral choice outcome ($0.17$, $SD=0.47$).

```{r}
## version used for power calcs: lm test of PraiseEmpathy on FEEL for Whites who pass attention checks and see Outgroup images on first trial
#"OLS estimate of the regression coefficient of peer praise on choosing to empathize:$0.17$, df=202, t=2.543, p=$0.0117$, CI= $[0.037, 0.296]$."
model1<-lm(describeORfeel~PraiseEmpathy,data=data6PE_1) ##***##
summary(model1)
confint(model1)
#0.16667
```

```{r costwage}
#"we estimated that choices to engage in empathy required a 10\% premium in wages to motivate our respondents": t, p, CI
t.test(data1$reservationpay_real, mu = 1, alternative = "greater")
```

